{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L3 M4.4: Compliance Maturity & Continuous Improvement\n",
    "\n",
    "## Learning Arc\n",
    "\n",
    "**Purpose:** Build a comprehensive compliance maturity assessment framework that helps GCC environments systematically evaluate and improve their compliance posture across five critical dimensions using PDCA cycles.\n",
    "\n",
    "**Concepts Covered:**\n",
    "- 5-level maturity framework (Ad-hoc ‚Üí Reactive ‚Üí Defined ‚Üí Measured ‚Üí Optimizing)\n",
    "- Five dimensions of compliance (People, Process, Technology, Metrics, Culture)\n",
    "- Weakest link rule (overall maturity = lowest dimension)\n",
    "- Gap analysis with prioritized improvement initiatives\n",
    "- Impact/effort matrix for initiative prioritization\n",
    "- PDCA cycle management (Plan-Do-Check-Act)\n",
    "- Compliance metrics tracking with trend detection\n",
    "- Maturity progression timelines (6-12 months per level)\n",
    "- Organizational vs. technical maturity constraints\n",
    "- Continuous improvement through systematic cycles\n",
    "\n",
    "**After Completing This Notebook:**\n",
    "- You will understand the 5-level compliance maturity model and its real-world application\n",
    "- You can assess your GCC's maturity across all five dimensions\n",
    "- You will identify your limiting dimension (weakest link blocking progress)\n",
    "- You can perform gap analysis between current and target states\n",
    "- You will create prioritized improvement roadmaps using impact/effort analysis\n",
    "- You can track 6 key compliance metrics with trend detection\n",
    "- You will implement PDCA cycles for sustainable continuous improvement\n",
    "- You can recognize common failure patterns and apply proven fixes\n",
    "- You will understand when maturity frameworks apply vs. tactical compliance\n",
    "\n",
    "**Context in Track L3.M4:**\n",
    "This module builds on M1 (Risk Taxonomy), M2 (Monitoring), and M3 (Enterprise Controls) to provide the meta-framework for continuous compliance improvement. It prepares you for advanced production RAG deployments in L4 modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Add src to path for imports\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.insert(0, '../src')\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')\n",
    "\n",
    "# OFFLINE mode for L3 consistency (no external services required)\n",
    "OFFLINE = os.getenv(\"OFFLINE\", \"true\").lower() == \"true\"\n",
    "\n",
    "# Optional Prometheus/Grafana for production dashboards\n",
    "PROMETHEUS_ENABLED = os.getenv(\"PROMETHEUS_ENABLED\", \"false\").lower() == \"true\"\n",
    "GRAFANA_ENABLED = os.getenv(\"GRAFANA_ENABLED\", \"false\").lower() == \"true\"\n",
    "\n",
    "if OFFLINE:\n",
    "    print(\"‚úì Running in OFFLINE mode (local processing)\")\n",
    "    print(\"  ‚Üí All core functionality works without external services\")\n",
    "    print(\"  ‚Üí Prometheus/Grafana disabled (optional for production dashboards)\")\n",
    "else:\n",
    "    print(\"‚úì Online mode\")\n",
    "    print(f\"  ‚Üí Prometheus: {'Enabled' if PROMETHEUS_ENABLED else 'Disabled'}\")\n",
    "    print(f\"  ‚Üí Grafana: {'Enabled' if GRAFANA_ENABLED else 'Disabled'}\")\n",
    "\n",
    "print(\"\\n‚úì Environment setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Import Core Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.l3_m4_compliance_maturity import (\n",
    "    MaturityLevel,\n",
    "    Dimension,\n",
    "    AssessmentQuestion,\n",
    "    MaturityAssessment,\n",
    "    GapAnalysis,\n",
    "    MetricsTracker,\n",
    "    ImprovementRoadmap,\n",
    "    PDCACycle,\n",
    "    Initiative,\n",
    "    generate_maturity_report,\n",
    "    calculate_overall_maturity,\n",
    "    create_improvement_plan\n",
    ")\n",
    "\n",
    "print(\"‚úì Imported compliance maturity framework modules\")\n",
    "print(\"\\nAvailable classes:\")\n",
    "print(\"  - MaturityLevel: 5-level enum (1=Ad-hoc ‚Üí 5=Optimizing)\")\n",
    "print(\"  - MaturityAssessment: 25-question assessment across 5 dimensions\")\n",
    "print(\"  - GapAnalysis: Compare current vs. target with priority ranking\")\n",
    "print(\"  - MetricsTracker: Track 6 key metrics with trend detection\")\n",
    "print(\"  - ImprovementRoadmap: Prioritized initiatives with timelines\")\n",
    "print(\"  - PDCACycle: Plan-Do-Check-Act cycle management\")\n",
    "print(\"\\nConvenience functions:\")\n",
    "print(\"  - generate_maturity_report(): One-step assessment report\")\n",
    "print(\"  - calculate_overall_maturity(): Get overall level (weakest link)\")\n",
    "print(\"  - create_improvement_plan(): Complete roadmap generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Understanding the 5-Level Maturity Model\n",
    "\n",
    "The maturity model progresses from reactive/chaotic (Level 1) to proactive/optimizing (Level 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the 5 maturity levels\n",
    "print(\"5-Level Compliance Maturity Framework\\n\" + \"=\"*50)\n",
    "\n",
    "for level in MaturityLevel:\n",
    "    print(f\"\\nLevel {level.value}: {level.description}\")\n",
    "\n",
    "# Real-world indicators\n",
    "print(\"\\n\\nReal-World Indicators (Technology Dimension Example):\\n\" + \"=\"*50)\n",
    "indicators = {\n",
    "    1: \"No PII detection before embedding documents\",\n",
    "    2: \"PII detection implemented but accuracy isn't validated\",\n",
    "    3: \"Automated compliance tests in CI/CD (OPA policies)\",\n",
    "    4: \"PII detection accuracy tracked and optimized (>99%)\",\n",
    "    5: \"AI-powered PII detection with continuous retraining\"\n",
    "}\n",
    "\n",
    "for level, indicator in indicators.items():\n",
    "    print(f\"L{level}: {indicator}\")\n",
    "\n",
    "# Expected: 5 levels printed with descriptions\n",
    "# Expected: Technology dimension indicators showing progression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Five Dimensions of Compliance Maturity\n",
    "\n",
    "**Critical Rule:** Overall maturity = LOWEST dimension score (weakest link determines ceiling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all five dimensions\n",
    "dimensions = Dimension.all_dimensions()\n",
    "\n",
    "print(\"Five Dimensions of Compliance Maturity\\n\" + \"=\"*50)\n",
    "for i, dim in enumerate(dimensions, 1):\n",
    "    print(f\"{i}. {dim}\")\n",
    "\n",
    "print(\"\\n\\nDimension Descriptions:\\n\" + \"=\"*50)\n",
    "\n",
    "dimension_info = {\n",
    "    \"People\": \"Training, expertise distribution, onboarding, responsibilities\",\n",
    "    \"Process\": \"Documentation, exception handling, SDLC integration, SLAs\",\n",
    "    \"Technology\": \"Automation (PII, RBAC, audit trails, testing, encryption)\",\n",
    "    \"Metrics\": \"Tracking, visibility, response to degradation, targets\",\n",
    "    \"Culture\": \"Leadership view, team reactions, failure handling, innovation\"\n",
    "}\n",
    "\n",
    "for dim, description in dimension_info.items():\n",
    "    print(f\"\\n{dim}:\")\n",
    "    print(f\"  {description}\")\n",
    "\n",
    "print(\"\\n\\n‚ö†Ô∏è  WEAKEST LINK RULE:\")\n",
    "print(\"If People=L4, Process=L4, Technology=L2, Metrics=L3, Culture=L4\")\n",
    "print(\"‚Üí Overall Maturity = L2 (Technology is limiting dimension)\")\n",
    "print(\"\\nThis prevents false confidence and focuses improvement efforts.\")\n",
    "\n",
    "# Expected: 5 dimensions listed\n",
    "# Expected: Weakest link rule explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: The Assessment Questionnaire (25 Questions)\n",
    "\n",
    "The assessment consists of 5 questions per dimension (total: 25 questions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize assessment and explore questionnaire structure\n",
    "assessment = MaturityAssessment()\n",
    "\n",
    "print(f\"Total Questions: {len(assessment.questions)}\")\n",
    "print(f\"Questions per Dimension: 5\\n\")\n",
    "\n",
    "# Show sample questions from each dimension\n",
    "print(\"Sample Questions by Dimension\\n\" + \"=\"*50)\n",
    "\n",
    "for dimension in Dimension.all_dimensions():\n",
    "    # Get first question for this dimension\n",
    "    sample_q = [q for q in assessment.questions if q.dimension == dimension][0]\n",
    "    \n",
    "    print(f\"\\n{dimension} Dimension:\")\n",
    "    print(f\"Q: {sample_q.question}\")\n",
    "    print(\"\\nLevel Indicators:\")\n",
    "    for level, indicator in sample_q.level_indicators.items():\n",
    "        print(f\"  L{level}: {indicator}\")\n",
    "\n",
    "print(\"\\n\\nEstimated Time: 15-20 minutes to complete all 25 questions\")\n",
    "\n",
    "# Expected: 25 total questions\n",
    "# Expected: Sample questions from each dimension with level indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Conducting a Maturity Assessment\n",
    "\n",
    "Let's simulate a Level 2 GCC assessment (typical 1-2 year old GCC in reactive mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example assessment from example_data.json\n",
    "with open('../example_data.json', 'r') as f:\n",
    "    example_data = json.load(f)\n",
    "\n",
    "# Use Level 2 GCC example\n",
    "level_2_responses = example_data['sample_assessment_responses']['level_2_gcc']['responses']\n",
    "\n",
    "print(\"Example: Level 2 GCC Assessment (Growing Phase, 1-2 years old)\\n\" + \"=\"*60)\n",
    "print(f\"Total responses: {len(level_2_responses)}\")\n",
    "print(\"\\nSample responses:\")\n",
    "for i, (question, level) in enumerate(list(level_2_responses.items())[:3], 1):\n",
    "    print(f\"{i}. {question}\")\n",
    "    print(f\"   Response: Level {level}\\n\")\n",
    "\n",
    "# Generate maturity report\n",
    "print(\"Generating maturity report...\\n\")\n",
    "report = generate_maturity_report(level_2_responses)\n",
    "\n",
    "print(\"Assessment Results\\n\" + \"=\"*60)\n",
    "print(f\"Assessment Date: {report['assessment_date']}\")\n",
    "print(f\"Responses Collected: {report['responses_collected']}\")\n",
    "print(f\"\\nDimension Scores:\")\n",
    "for dim in ['people', 'process', 'technology', 'metrics', 'culture']:\n",
    "    print(f\"  {dim.capitalize()}: {report['scores'][dim]:.1f}\")\n",
    "\n",
    "print(f\"\\nOverall Maturity: Level {report['scores']['overall']}\")\n",
    "print(f\"Limiting Dimension: {report['limiting_dimension']}\")\n",
    "print(f\"Next Target Level: {report['next_target_level']}\")\n",
    "print(f\"Estimated Timeline: {report['estimated_timeline']}\")\n",
    "\n",
    "print(f\"\\nTop 3 Recommendations:\")\n",
    "for i, rec in enumerate(report['recommendations'][:3], 1):\n",
    "    print(f\"{i}. {rec}\")\n",
    "\n",
    "# Expected: Level 2 across all dimensions\n",
    "# Expected: Recommendations for reaching Level 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Understanding the Weakest Link Rule\n",
    "\n",
    "Let's see how the weakest link rule works with unbalanced maturity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mixed maturity example (strong People/Culture, weak Technology)\n",
    "mixed_responses = example_data['sample_assessment_responses']['mixed_maturity_gcc']['responses']\n",
    "\n",
    "print(\"Example: Unbalanced Maturity GCC\\n\" + \"=\"*60)\n",
    "print(\"Scenario: Strong People/Culture investment, but technology lags\\n\")\n",
    "\n",
    "# Calculate maturity\n",
    "assessment_mixed = MaturityAssessment()\n",
    "assessment_mixed.collect_responses(mixed_responses)\n",
    "scores_mixed = assessment_mixed.calculate_maturity_scores()\n",
    "\n",
    "print(\"Dimension Scores:\")\n",
    "print(f\"  People:     {scores_mixed.people:.1f}  ‚Üê Strong\")\n",
    "print(f\"  Process:    {scores_mixed.process:.1f}\")\n",
    "print(f\"  Technology: {scores_mixed.technology:.1f}  ‚Üê WEAKEST LINK\")\n",
    "print(f\"  Metrics:    {scores_mixed.metrics:.1f}\")\n",
    "print(f\"  Culture:    {scores_mixed.culture:.1f}  ‚Üê Strong\")\n",
    "\n",
    "print(f\"\\nüîç Overall Maturity: Level {scores_mixed.overall}\")\n",
    "print(\"\\n‚ö†Ô∏è  Key Insight:\")\n",
    "print(\"   Even with Level 4 People and Culture, overall maturity is Level 2\")\n",
    "print(\"   because Technology (weakest link) is at Level 2.\")\n",
    "print(\"\\n   ‚Üí Improvement Priority: Focus on Technology dimension\")\n",
    "print(\"   ‚Üí Until Technology reaches L3, you cannot claim L3 maturity\")\n",
    "\n",
    "# Expected: Technology at 2.0, People and Culture at 4.0\n",
    "# Expected: Overall = 2 (weakest link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Gap Analysis\n",
    "\n",
    "Identify gaps between current and target state, with priority ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform gap analysis: Current L2 ‚Üí Target L4\n",
    "gap_analysis = GapAnalysis(scores_mixed, target_level=4)\n",
    "gaps = gap_analysis.identify_gaps()\n",
    "\n",
    "print(\"Gap Analysis: Current State ‚Üí Target Level 4\\n\" + \"=\"*60)\n",
    "print(f\"Gaps Identified: {gaps['gaps_identified']}\")\n",
    "print(f\"Total Effort Estimate: {gaps['total_effort_estimate']}\\n\")\n",
    "\n",
    "print(\"Dimension Gaps (sorted by size):\\n\")\n",
    "for dimension, gap_info in gaps['dimension_gaps'].items():\n",
    "    print(f\"{dimension}:\")\n",
    "    print(f\"  Current: {gap_info['current']:.1f}\")\n",
    "    print(f\"  Target:  {gap_info['target']}\")\n",
    "    print(f\"  Gap:     {gap_info['gap']:.1f} levels ({gap_info['priority']} priority)\")\n",
    "    print()\n",
    "\n",
    "print(\"Recommended Sequence for Closing Gaps:\")\n",
    "for i, step in enumerate(gaps['recommended_sequence'], 1):\n",
    "    print(f\"{i}. {step}\")\n",
    "\n",
    "print(\"\\nüí° Priority Explanation:\")\n",
    "print(\"   - Culture & People first (foundation for change)\")\n",
    "   \"   - Process next (standardization)\")\n",
    "print(\"   - Technology & Metrics last (enabled by foundation)\")\n",
    "\n",
    "# Expected: Technology has largest gap (2.0 levels)\n",
    "# Expected: Sequence prioritizes foundation dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Creating an Improvement Roadmap\n",
    "\n",
    "Generate prioritized initiatives using impact/effort matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create improvement roadmap\n",
    "roadmap = ImprovementRoadmap(gaps)\n",
    "initiatives = roadmap.create_initiatives(max_concurrent=3)\n",
    "roadmap_plan = roadmap.generate_roadmap()\n",
    "\n",
    "print(\"Improvement Roadmap\\n\" + \"=\"*60)\n",
    "print(f\"Total Initiatives: {roadmap_plan['total_initiatives']}\")\n",
    "print(f\"Timeline: {roadmap_plan['timeline_weeks']} weeks\\n\")\n",
    "\n",
    "print(\"Prioritized Initiatives (by Impact/Effort ratio):\\n\")\n",
    "for i, init in enumerate(roadmap_plan['initiatives'], 1):\n",
    "    print(f\"{i}. {init['title']}\")\n",
    "    print(f\"   Dimension:  {init['dimension']}\")\n",
    "    print(f\"   Timeline:   {init['weeks']} weeks\")\n",
    "    print(f\"   Impact:     {init['impact']}\")\n",
    "    print(f\"   Effort:     {init['effort']}\")\n",
    "    print(f\"   Owner:      {init['owner']}\")\n",
    "    print()\n",
    "\n",
    "print(\"Quarterly Breakdown:\\n\")\n",
    "for quarter, initiatives_list in roadmap_plan['quarterly_breakdown'].items():\n",
    "    if initiatives_list:\n",
    "        print(f\"{quarter}:\")\n",
    "        for init in initiatives_list:\n",
    "            print(f\"  - {init}\")\n",
    "        print()\n",
    "\n",
    "print(\"üí° Impact/Effort Prioritization:\")\n",
    "print(\"   High Impact + Low Effort = Quick wins (do first)\")\n",
    "print(\"   High Impact + High Effort = Strategic (plan carefully)\")\n",
    "print(\"   Low Impact + High Effort = Avoid (low ROI)\")\n",
    "\n",
    "# Expected: 3-6 initiatives prioritized by impact/effort\n",
    "# Expected: Quarterly breakdown for planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10: Metrics Tracking\n",
    "\n",
    "Track 6 key compliance metrics with trend detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics tracker\n",
    "metrics_tracker = MetricsTracker()\n",
    "\n",
    "print(\"6 Key Compliance Metrics\\n\" + \"=\"*60)\n",
    "\n",
    "# Show initial state\n",
    "summary = metrics_tracker.get_metrics_summary()\n",
    "\n",
    "print(\"Metric Definitions:\\n\")\n",
    "for metric_name, metric_info in summary['metrics'].items():\n",
    "    print(f\"{metric_info['current']} (not set yet)\")\n",
    "    print(f\"  Target: {metric_info['target']}{metric_info['unit']}\")\n",
    "    print()\n",
    "\n",
    "# Simulate metric updates over time (load from example data)\n",
    "metric_updates = example_data['sample_metric_updates']\n",
    "\n",
    "print(\"\\nSimulating 6 weeks of metric tracking...\\n\")\n",
    "\n",
    "# Update PII detection accuracy (improving trend)\n",
    "pii_updates = metric_updates[0]['values_over_time']\n",
    "for update in pii_updates[-3:]:  # Last 3 weeks for trend\n",
    "    metrics_tracker.update_metric('pii_detection_accuracy', update['value'])\n",
    "\n",
    "# Update access violations (improving trend)\n",
    "access_updates = metric_updates[2]['values_over_time']\n",
    "for update in access_updates[-3:]:\n",
    "    metrics_tracker.update_metric('access_violations', update['value'])\n",
    "\n",
    "# Get updated summary\n",
    "updated_summary = metrics_tracker.get_metrics_summary()\n",
    "\n",
    "print(\"Current Metrics Status:\\n\")\n",
    "for metric_name, metric_info in updated_summary['metrics'].items():\n",
    "    status = \"‚úì\" if metric_info['meeting_target'] else \"‚úó\"\n",
    "    trend_symbol = {\"improving\": \"‚Üó\", \"stable\": \"‚Üí\", \"degrading\": \"‚Üò\"}[metric_info['trend']]\n",
    "    \n",
    "    print(f\"{status} {metric_name}:\")\n",
    "    print(f\"    Current: {metric_info['current']}{metric_info['unit']} {trend_symbol}\")\n",
    "    print(f\"    Target:  {metric_info['target']}{metric_info['unit']}\")\n",
    "\n",
    "print(f\"\\nMetrics Meeting Target: {updated_summary['meeting_target']}/{updated_summary['total_metrics']}\")\n",
    "\n",
    "# Expected: Metrics with improving/stable trends\n",
    "# Expected: Some metrics meeting target, others in progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 11: Detecting Metric Regressions\n",
    "\n",
    "Identify metrics moving in the wrong direction (degrading trends)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a degrading metric (compliance test coverage dropping)\n",
    "print(\"Simulating Metric Regression Scenario\\n\" + \"=\"*60)\n",
    "print(\"Scenario: Compliance test coverage starts degrading...\\n\")\n",
    "\n",
    "# Create degrading trend (coverage dropping over 3 weeks)\n",
    "metrics_tracker.update_metric('compliance_test_coverage', 96.0)\n",
    "metrics_tracker.update_metric('compliance_test_coverage', 94.5)\n",
    "metrics_tracker.update_metric('compliance_test_coverage', 92.0)\n",
    "\n",
    "print(\"Week 1: 96.0% (meeting target)\")\n",
    "print(\"Week 2: 94.5% (below 95% target) ‚ö†Ô∏è\")\n",
    "print(\"Week 3: 92.0% (continuing to drop) üö®\\n\")\n",
    "\n",
    "# Detect regressions\n",
    "regressions = metrics_tracker.detect_regressions()\n",
    "\n",
    "if regressions:\n",
    "    print(f\"‚ö†Ô∏è  ALERT: {len(regressions)} metric(s) degrading!\\n\")\n",
    "    for regression in regressions:\n",
    "        print(f\"   {regression}\")\n",
    "    \n",
    "    print(\"\\nüîç Required Actions:\")\n",
    "    print(\"   1. Root cause analysis within 48 hours\")\n",
    "    print(\"   2. Create emergency initiative if needed\")\n",
    "    print(\"   3. Track recovery in next PDCA cycle\")\n",
    "else:\n",
    "    print(\"‚úì No regressions detected - all metrics stable or improving\")\n",
    "\n",
    "print(\"\\nüí° Regression Detection Rule:\")\n",
    "print(\"   3 consecutive datapoints showing degradation = ALERT\")\n",
    "print(\"   This prevents false alarms from single anomalies\")\n",
    "\n",
    "# Expected: 1 regression detected (compliance_test_coverage)\n",
    "# Expected: Action recommendations displayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 12: PDCA Cycle - Complete Workflow\n",
    "\n",
    "Implement a full Plan-Do-Check-Act cycle for continuous improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PDCA cycle for Q1 2025\n",
    "pdca_cycle = PDCACycle(\"2025-Q1\", duration_weeks=12)\n",
    "\n",
    "print(\"PDCA Cycle: 2025-Q1 (12 weeks)\\n\" + \"=\"*60)\n",
    "\n",
    "# PLAN PHASE\n",
    "print(\"\\nüìã PLAN Phase (Weeks 1-2)\\n\")\n",
    "print(\"Actions:\")\n",
    "print(\"  1. Conduct maturity assessment ‚Üí Overall Level 2 (Technology limiting)\")\n",
    "print(\"  2. Gap analysis ‚Üí Target Level 3 requires Technology improvement\")\n",
    "print(\"  3. Select top 3 initiatives from roadmap\")\n",
    "print(\"  4. Assign owners and set SMART goals\\n\")\n",
    "\n",
    "# Use initiatives from improvement roadmap\n",
    "selected_initiatives = initiatives[:3]  # Top 3 from earlier roadmap\n",
    "pdca_cycle.plan(selected_initiatives)\n",
    "\n",
    "print(\"Selected Initiatives:\")\n",
    "for i, init in enumerate(pdca_cycle.initiatives, 1):\n",
    "    print(f\"  {i}. {init.title}\")\n",
    "    print(f\"     Owner: {init.owner} | Timeline: {init.timeline_weeks} weeks\")\n",
    "    print(f\"     Impact: {init.impact} | Effort: {init.effort}\")\n",
    "\n",
    "# DO PHASE\n",
    "print(\"\\n\\n‚öôÔ∏è  DO Phase (Weeks 3-8)\\n\")\n",
    "pdca_cycle.do()\n",
    "print(\"Actions:\")\n",
    "print(\"  - Execute initiatives according to plan\")\n",
    "print(\"  - Track metrics weekly (all 6 compliance metrics)\")\n",
    "print(\"  - Hold bi-weekly progress reviews\")\n",
    "print(\"  - Document challenges and lessons learned\\n\")\n",
    "\n",
    "print(\"Execution Status:\")\n",
    "for init in pdca_cycle.initiatives:\n",
    "    print(f\"  {init.title}: {init.status}\")\n",
    "\n",
    "# Simulate completion\n",
    "pdca_cycle.initiatives[0].status = \"Completed\"\n",
    "pdca_cycle.initiatives[1].status = \"Completed\"\n",
    "pdca_cycle.initiatives[2].status = \"In Progress\"  # One didn't finish\n",
    "\n",
    "# CHECK PHASE\n",
    "print(\"\\n\\nüìä CHECK Phase (Weeks 9-10)\\n\")\n",
    "metrics_summary = metrics_tracker.get_metrics_summary()\n",
    "results = pdca_cycle.check(metrics_summary)\n",
    "\n",
    "print(\"Measuring Results Against Goals:\\n\")\n",
    "print(f\"  Completed Initiatives: {results['completed_initiatives']}/{results['total_initiatives']}\")\n",
    "print(f\"  Metrics Meeting Target: {results['metrics_meeting_target']}/{results['total_metrics']}\")\n",
    "print(f\"  Degrading Metrics: {results['degrading_metrics']}\")\n",
    "\n",
    "print(\"\\nExample Results:\")\n",
    "print(\"  Initiative 1 (PII Upgrade): ‚úì Completed, accuracy 95% ‚Üí 99.2%\")\n",
    "print(\"  Initiative 2 (Grafana Dashboard): ‚úì Completed, adopted by all teams\")\n",
    "print(\"  Initiative 3 (OPA Policies): ‚úó In Progress, needed more time\")\n",
    "\n",
    "# ACT PHASE\n",
    "print(\"\\n\\nüîÑ ACT Phase (Weeks 11-12)\\n\")\n",
    "actions = pdca_cycle.act()\n",
    "\n",
    "print(\"Actions for Next Cycle:\\n\")\n",
    "for i, action in enumerate(actions, 1):\n",
    "    print(f\"  {i}. {action}\")\n",
    "\n",
    "print(\"\\nStandardization:\")\n",
    "print(\"  - Document NER-based PII detection as new standard\")\n",
    "print(\"  - Update onboarding materials with Grafana dashboard\")\n",
    "print(\"  - Share lessons learned from OPA rollout (underestimated complexity)\")\n",
    "\n",
    "print(\"\\nNext Cycle Planning:\")\n",
    "print(\"  - Continue OPA initiative (add 6 more weeks)\")\n",
    "print(\"  - Start ABAC implementation (Technology dimension)\")\n",
    "print(\"  - Re-assess maturity (expecting Technology: 2.0 ‚Üí 2.7)\")\n",
    "\n",
    "print(\"\\n\\nüí° PDCA Success Factors:\")\n",
    "print(\"   ‚úì Actually MEASURE in Check (don't skip!)\")\n",
    "print(\"   ‚úì ACT on lessons (don't just document)\")\n",
    "print(\"   ‚úì Limit initiatives (3-4 max, focus beats scope)\")\n",
    "print(\"   ‚úì Repeat for 2-3 years (each level takes 6-12 months)\")\n",
    "\n",
    "# Expected: Complete PDCA cycle demonstrated\n",
    "# Expected: 2/3 initiatives completed, 1 continued to next cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 13: Using Convenience Functions\n",
    "\n",
    "The framework provides one-step functions for common workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-step improvement plan generation\n",
    "print(\"Creating Complete Improvement Plan (One Function Call)\\n\" + \"=\"*60)\n",
    "\n",
    "improvement_plan = create_improvement_plan(\n",
    "    current_responses=level_2_responses,\n",
    "    target_level=4,\n",
    "    max_initiatives=3\n",
    ")\n",
    "\n",
    "print(\"\\nCurrent Maturity:\")\n",
    "print(f\"  Overall Level: {improvement_plan['current_maturity']['overall']}\")\n",
    "print(f\"  People: {improvement_plan['current_maturity']['people']:.1f}\")\n",
    "print(f\"  Technology: {improvement_plan['current_maturity']['technology']:.1f}\")\n",
    "\n",
    "print(f\"\\nTarget Level: {improvement_plan['target_level']}\")\n",
    "print(f\"Estimated Timeline: {improvement_plan['estimated_timeline']}\")\n",
    "\n",
    "print(f\"\\nTop 3 Initiatives:\")\n",
    "for i, init in enumerate(improvement_plan['improvement_roadmap']['initiatives'][:3], 1):\n",
    "    print(f\"  {i}. {init['title']} ({init['dimension']})\")\n",
    "\n",
    "print(\"\\nüí° Convenience Functions Available:\")\n",
    "print(\"   - generate_maturity_report(): Full assessment report\")\n",
    "print(\"   - calculate_overall_maturity(): Just the overall level (quick)\")\n",
    "print(\"   - create_improvement_plan(): Complete roadmap in one call\")\n",
    "\n",
    "# Expected: Complete plan generated with one function call\n",
    "# Expected: Ready to use for PDCA planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 14: Common Failure Scenarios & Fixes\n",
    "\n",
    "Learn from real-world failures to avoid them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load failure scenarios from example data\n",
    "failures = example_data['common_failure_scenarios']\n",
    "\n",
    "print(\"Common PDCA Failure Scenarios\\n\" + \"=\"*60)\n",
    "\n",
    "for i, failure in enumerate(failures, 1):\n",
    "    print(f\"\\nFailure {i}: {failure['failure']}\")\n",
    "    print(f\"Symptoms: {failure['symptoms']}\")\n",
    "    print(f\"Impact:   {failure['impact']}\")\n",
    "    print(f\"Fix:      {failure['fix']}\")\n",
    "\n",
    "print(\"\\n\\nüéØ Pattern Recognition:\")\n",
    "print(\"   - Skipping phases (especially Check/Act) = no learning\")\n",
    "print(\"   - Overcommitment = low completion rate = burnout\")\n",
    "print(\"   - No monitoring = regression unnoticed = backsliding\")\n",
    "print(\"   - False confidence = external audit surprises\")\n",
    "\n",
    "print(\"\\n‚úì Success is Boring:\")\n",
    "print(\"   Pick 3-4 improvements per quarter\")\n",
    "print(\"   Execute well, measure, adjust\")\n",
    "print(\"   Repeat for 2-3 years\")\n",
    "print(\"   Each maturity level takes 6-12 months (can't rush culture)\")\n",
    "\n",
    "# Expected: 4 failure scenarios with fixes\n",
    "# Expected: Patterns and success formula highlighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 15: Decision Card - When to Use This Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compliance Maturity Framework - Decision Card\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"\\n‚úÖ USE WHEN:\\n\")\n",
    "use_cases = [\n",
    "    \"Your GCC is at least 1 year old (organizational maturity needed)\",\n",
    "    \"You have 3+ audit findings per audit and want systematic improvement\",\n",
    "    \"Leadership willing to commit to 2-3 years of continuous improvement\",\n",
    "    \"You need to justify compliance investments with data\",\n",
    "    \"Multiple compliance dimensions are weak (holistic approach needed)\",\n",
    "    \"You're scaling from 50 to 500+ employees\",\n",
    "    \"Parent company requires maturity assessment\",\n",
    "    \"Clients ask about compliance maturity level\",\n",
    "    \"You want to prevent regression after reaching Level 3-4\"\n",
    "]\n",
    "\n",
    "for use_case in use_cases:\n",
    "    print(f\"   ‚Ä¢ {use_case}\")\n",
    "\n",
    "print(\"\\n‚ùå DON'T USE WHEN:\\n\")\n",
    "avoid_cases = [\n",
    "    \"Your GCC is <6 months old (focus on survival first)\",\n",
    "    \"You have zero audit findings (no urgency, premature optimization)\",\n",
    "    \"Leadership wants 'quick compliance fix' (cultural change takes time)\",\n",
    "    \"You need immediate compliance for single regulation (use targeted controls)\",\n",
    "    \"Team size <10 people (overhead too high, informal processes sufficient)\",\n",
    "    \"You're already at Level 5 across all dimensions (maintain, don't re-assess)\",\n",
    "    \"Budget/headcount for compliance is zero (assessment without resources = frustration)\"\n",
    "]\n",
    "\n",
    "for avoid_case in avoid_cases:\n",
    "    print(f\"   ‚Ä¢ {avoid_case}\")\n",
    "\n",
    "print(\"\\n‚öñÔ∏è  TRADE-OFFS:\\n\")\n",
    "print(\"Cost:\")\n",
    "print(\"   Small GCC:  ‚Çπ5,000/month ($60 USD)\")\n",
    "print(\"   Medium GCC: ‚Çπ15,000/month ($185 USD)\")\n",
    "print(\"   Large GCC:  ‚Çπ40,000/month ($490 USD)\")\n",
    "\n",
    "print(\"\\nTime:\")\n",
    "print(\"   Each maturity level: 6-12 months (can't be rushed)\")\n",
    "print(\"   PDCA cycle: 12 weeks minimum\")\n",
    "print(\"   Assessment: 15-20 minutes per person\")\n",
    "\n",
    "print(\"\\nComplexity:\")\n",
    "print(\"   Initial setup: 2-4 weeks\")\n",
    "print(\"   Ongoing overhead: 4-8 hours/month\")\n",
    "print(\"   Requires: Dedicated compliance champion (20-40% role)\")\n",
    "\n",
    "print(\"\\nüéØ Key Insight:\")\n",
    "print(\"   'Organizational maturity limits technical maturity'\")\n",
    "print(\"   Don't expect Level 4 RAG systems in Level 2 GCCs\")\n",
    "\n",
    "# Expected: Clear decision criteria for framework adoption\n",
    "# Expected: Trade-offs quantified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 16: Maturity Timeline - GCC Evolution\n",
    "\n",
    "Understand typical maturity progression over GCC lifecycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GCC Maturity Evolution Timeline\\n\" + \"=\"*60)\n",
    "\n",
    "timeline = [\n",
    "    {\n",
    "        \"phase\": \"Year 0-1: Startup GCC\",\n",
    "        \"maturity\": \"Level 1-2\",\n",
    "        \"characteristics\": [\n",
    "            \"Focus on proving value to parent company\",\n",
    "            \"Compliance minimal, ad-hoc\",\n",
    "            \"Audit findings: 15-25 per audit\",\n",
    "            \"Parent company: 'Just get it done'\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Year 1-2: Growing GCC\",\n",
    "        \"maturity\": \"Level 2-3\",\n",
    "        \"characteristics\": [\n",
    "            \"First formal audit of operations\",\n",
    "            \"Compliance officer hired\",\n",
    "            \"Basic processes documented\",\n",
    "            \"Audit findings: 8-15 per audit\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Year 2-4: Mature GCC\",\n",
    "        \"maturity\": \"Level 3-4\",\n",
    "        \"characteristics\": [\n",
    "            \"Compliance becomes systematic\",\n",
    "            \"Compliance team of 3-5 people\",\n",
    "            \"Automated monitoring in place\",\n",
    "            \"Audit findings: 3-8 per audit\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Year 4+: Enterprise GCC\",\n",
    "        \"maturity\": \"Level 4-5\",\n",
    "        \"characteristics\": [\n",
    "            \"GCC as center of excellence\",\n",
    "            \"Compliance is competitive advantage\",\n",
    "            \"Direct client interaction on compliance\",\n",
    "            \"Audit findings: 0-3 per audit\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "for stage in timeline:\n",
    "    print(f\"\\n{stage['phase']}\")\n",
    "    print(f\"Typical Maturity: {stage['maturity']}\\n\")\n",
    "    for char in stage['characteristics']:\n",
    "        print(f\"   ‚Ä¢ {char}\")\n",
    "\n",
    "print(\"\\n\\n‚ö†Ô∏è  Reality Check:\")\n",
    "print(\"   You CANNOT skip levels or rush maturity\")\n",
    "print(\"   Level 1 ‚Üí 2: 6-12 months (organizational buy-in)\")\n",
    "print(\"   Level 2 ‚Üí 3: 9-12 months (process standardization)\")\n",
    "print(\"   Level 3 ‚Üí 4: 12-18 months (metrics maturity)\")\n",
    "print(\"   Level 4 ‚Üí 5: 18-24 months (culture change is slow)\")\n",
    "\n",
    "print(\"\\n‚úì 'Good Enough' Targets:\")\n",
    "print(\"   Most GCCs: Level 3 is sufficient (defined, proactive)\")\n",
    "print(\"   Enterprise GCCs: Level 4 target (measured, data-driven)\")\n",
    "print(\"   Center of Excellence: Level 5 aspiration (continuous innovation)\")\n",
    "\n",
    "# Expected: Timeline showing 4-5 year maturity journey\n",
    "# Expected: Realistic expectations set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 17: Integration with M1-M3 Modules\n",
    "\n",
    "How this maturity framework connects to previous L3 modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"L3 M4.4 Integration with Previous Modules\\n\" + \"=\"*60)\n",
    "\n",
    "integrations = [\n",
    "    {\n",
    "        \"module\": \"M1: Risk Taxonomy\",\n",
    "        \"connection\": \"People Dimension\",\n",
    "        \"how\": \"Maturity L3+ requires team understanding of all risk categories from M1\"\n",
    "    },\n",
    "    {\n",
    "        \"module\": \"M2: Monitoring & Observability\",\n",
    "        \"connection\": \"Metrics Dimension\",\n",
    "        \"how\": \"M2 Prometheus/Grafana setup enables L4 metrics-driven maturity\"\n",
    "    },\n",
    "    {\n",
    "        \"module\": \"M3: Enterprise Controls\",\n",
    "        \"connection\": \"Technology Dimension\",\n",
    "        \"how\": \"M3 controls (PII, RBAC, audit) are the foundation for L3+ technology maturity\"\n",
    "    },\n",
    "    {\n",
    "        \"module\": \"M4.4: Maturity Framework (this module)\",\n",
    "        \"connection\": \"Process & Culture Dimensions\",\n",
    "        \"how\": \"Provides meta-framework for continuous improvement of M1-M3 implementations\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for integration in integrations:\n",
    "    print(f\"\\n{integration['module']}\")\n",
    "    print(f\"   Maps to: {integration['connection']}\")\n",
    "    print(f\"   How: {integration['how']}\")\n",
    "\n",
    "print(\"\\n\\nüîó Holistic View:\")\n",
    "print(\"   M1 (Taxonomy) + M2 (Monitoring) + M3 (Controls) + M4 (Maturity)\")\n",
    "print(\"   = Complete compliance framework for production RAG systems\")\n",
    "\n",
    "print(\"\\nüìä Maturity Assessment Example:\")\n",
    "print(\"   Technology Dimension Questions Reference M3:\")\n",
    "print(\"   - 'How automated is your PII detection?' ‚Üí M3 PII module\")\n",
    "print(\"   - 'How complete are your audit trails?' ‚Üí M3 audit logging\")\n",
    "print(\"   - 'How is access control implemented?' ‚Üí M3 RBAC\")\n",
    "\n",
    "print(\"\\n   Metrics Dimension Questions Reference M2:\")\n",
    "print(\"   - 'What compliance metrics do you track?' ‚Üí M2 Prometheus\")\n",
    "print(\"   - 'How visible are compliance metrics?' ‚Üí M2 Grafana dashboards\")\n",
    "\n",
    "print(\"\\nüí° Integration Best Practice:\")\n",
    "print(\"   Use M4 maturity assessment AFTER implementing M1-M3\")\n",
    "print(\"   Then use PDCA cycles to continuously improve M1-M3 implementations\")\n",
    "\n",
    "# Expected: Clear connections to M1, M2, M3\n",
    "# Expected: Integration examples shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 18: Next Steps & Production Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Next Steps for Production Deployment\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"\\n1. IMMEDIATE (This Week):\")\n",
    "print(\"   ‚òê Customize 25-question assessment for your industry\")\n",
    "print(\"   ‚òê Conduct pilot assessment with 5-10 people\")\n",
    "print(\"   ‚òê Set realistic target maturity level (don't over-commit)\")\n",
    "print(\"   ‚òê Configure metric targets in .env file\")\n",
    "\n",
    "print(\"\\n2. SHORT-TERM (Next 2 Weeks):\")\n",
    "print(\"   ‚òê Full team assessment (all 25 questions)\")\n",
    "print(\"   ‚òê Generate maturity report and gap analysis\")\n",
    "print(\"   ‚òê Present findings to leadership (manage expectations!)\")\n",
    "print(\"   ‚òê Create first improvement roadmap (max 3-4 initiatives)\")\n",
    "\n",
    "print(\"\\n3. MEDIUM-TERM (First PDCA Cycle - 12 Weeks):\")\n",
    "print(\"   ‚òê Plan Phase: Select initiatives, assign owners, set goals\")\n",
    "print(\"   ‚òê Do Phase: Execute initiatives, track metrics weekly\")\n",
    "print(\"   ‚òê Check Phase: Measure results vs. goals (don't skip!)\")\n",
    "print(\"   ‚òê Act Phase: Standardize successes, plan next cycle\")\n",
    "\n",
    "print(\"\\n4. LONG-TERM (2-3 Years):\")\n",
    "print(\"   ‚òê Execute 8-12 PDCA cycles\")\n",
    "print(\"   ‚òê Advance 1-2 maturity levels (realistic expectation)\")\n",
    "print(\"   ‚òê Balance all five dimensions (avoid lopsided maturity)\")\n",
    "print(\"   ‚òê External audit validation (verify self-assessment)\")\n",
    "\n",
    "print(\"\\n\\nüöÄ Optional Enhancements:\")\n",
    "print(\"   ‚Ä¢ Deploy Prometheus Pushgateway for metrics (production)\")\n",
    "print(\"   ‚Ä¢ Create Grafana dashboards for real-time visibility\")\n",
    "print(\"   ‚Ä¢ Integrate with LMS for training tracking\")\n",
    "print(\"   ‚Ä¢ Automate assessment collection (Google Forms ‚Üí API)\")\n",
    "print(\"   ‚Ä¢ Build custom reports for parent company/clients\")\n",
    "\n",
    "print(\"\\nüìö Further Learning:\")\n",
    "print(\"   ‚Ä¢ CMMI (Capability Maturity Model Integration) - original framework\")\n",
    "print(\"   ‚Ä¢ ISO 27001 - Information security management maturity\")\n",
    "print(\"   ‚Ä¢ NIST Cybersecurity Framework - Risk management maturity\")\n",
    "print(\"   ‚Ä¢ DevOps Research & Assessment (DORA) metrics\")\n",
    "\n",
    "print(\"\\n‚úì Success Metrics for This Module:\")\n",
    "print(\"   ‚òë Completed maturity assessment in <20 minutes\")\n",
    "print(\"   ‚òë Identified limiting dimension accurately\")\n",
    "print(\"   ‚òë Generated prioritized improvement roadmap\")\n",
    "print(\"   ‚òë Tracked >3 metrics with trend detection\")\n",
    "print(\"   ‚òë Understand PDCA cycle execution\")\n",
    "print(\"   ‚òë Can recognize failure patterns and apply fixes\")\n",
    "\n",
    "print(\"\\nüéì Congratulations!\")\n",
    "print(\"   You've completed L3 M4.4: Compliance Maturity & Continuous Improvement\")\n",
    "print(\"   You're ready to implement systematic compliance improvement in production!\")\n",
    "\n",
    "# Expected: Clear actionable next steps\n",
    "# Expected: Timeline from pilot to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **5-Level Maturity Framework** - From Ad-hoc (L1) to Optimizing (L5)\n",
    "2. **Five Dimensions** - People, Process, Technology, Metrics, Culture\n",
    "3. **Weakest Link Rule** - Overall maturity = lowest dimension (prevents false confidence)\n",
    "4. **25-Question Assessment** - Comprehensive evaluation across all dimensions\n",
    "5. **Gap Analysis** - Prioritized improvements based on current vs. target state\n",
    "6. **Improvement Roadmaps** - Impact/effort matrix for initiative prioritization\n",
    "7. **Metrics Tracking** - 6 key compliance metrics with trend detection\n",
    "8. **PDCA Cycles** - Plan-Do-Check-Act for continuous improvement\n",
    "9. **Failure Patterns** - Common mistakes and proven fixes\n",
    "10. **Decision Card** - When to use (and when not to use) this framework\n",
    "\n",
    "**Key Takeaway:** \"Success is boring‚Äîpick 3-4 specific improvements per quarter, execute well, measure, adjust, and repeat for 2-3 years.\"\n",
    "\n",
    "**Remember:** Each maturity level takes 6-12 months. You cannot skip levels or rush culture change. Level 3 is \"good enough\" for most GCCs.\n",
    "\n",
    "**Next:** Apply this framework to your GCC, execute your first PDCA cycle, and track progress systematically!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
