{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L3 M3.4: Incident Response & Breach Notification\n",
    "\n",
    "## Learning Arc\n",
    "\n",
    "**Purpose:** Build a production-grade incident response and breach notification system for GCC compliance environments, automating the detection, classification, response workflow, and regulatory notification process for security and compliance incidents.\n",
    "\n",
    "**Concepts Covered:**\n",
    "- 4-tier incident severity classification (P0 Critical, P1 High, P2 Medium, P3 Low)\n",
    "- 6-phase incident response workflow (Detection, Containment, Investigation, Eradication, Recovery, Post-Mortem)\n",
    "- Automated breach notification for GDPR Article 33/34 and DPDPA compliance\n",
    "- Multi-tenant incident isolation and tracking\n",
    "- Regulatory deadline management (72-hour GDPR notification requirement)\n",
    "- Incident audit trail and documentation\n",
    "- Root cause analysis and preventive measures\n",
    "\n",
    "**After Completing This Notebook:**\n",
    "- You will understand how to classify incident severity based on impact assessment\n",
    "- You can implement a structured 6-phase incident response workflow\n",
    "- You will recognize when regulatory breach notification is required\n",
    "- You can automate GDPR/DPDPA notification with deadline tracking\n",
    "- You will implement multi-tenant incident isolation\n",
    "- You can generate post-mortem reports with lessons learned\n",
    "- You will build production-ready incident response systems for GCC environments\n",
    "\n",
    "**Context in Track L3.M3:**\n",
    "This module builds on M3.3 (Audit Logging & SIEM) and completes the monitoring & reporting track by adding incident response capabilities. You've learned to log compliance events - now you'll handle security incidents and breach notifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add src to path for imports\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.insert(0, '../src')\n",
    "\n",
    "# This module has no external service dependencies\n",
    "# All incident response processing is local\n",
    "print(\"✓ No external services required\")\n",
    "print(\"  → All incident classification and workflow management is local\")\n",
    "print(\"  → Ready to explore incident response automation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Understanding Incident Severity Classification\n",
    "\n",
    "### Why Classification Matters\n",
    "\n",
    "In GCC environments, not all incidents are equal. A configuration drift in a test environment (P3) requires different handling than a production data breach affecting 10,000 users (P0).\n",
    "\n",
    "**The 4-Tier System:**\n",
    "- **P0 (Critical):** Data breaches, full outages, regulatory violations - immediate escalation required\n",
    "- **P1 (High):** Partial data exposure, service degradation, security incidents - urgent response\n",
    "- **P2 (Medium):** Minor security events, isolated tenant issues - standard response\n",
    "- **P3 (Low):** Low-impact incidents, configuration issues - routine handling\n",
    "\n",
    "**Real-world Impact:**\n",
    "- P0 incident: CFO gets paged at 2 AM, war room activated, regulatory lawyers on standby\n",
    "- P3 incident: Ticket created, assigned to engineer, fixed during business hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l3_m3_monitoring_reporting import IncidentClassifier, IncidentType, IncidentSeverity\n",
    "\n",
    "# Example 1: P0 Classification - Large data breach\n",
    "severity_p0 = IncidentClassifier.classify_incident(\n",
    "    incident_type=IncidentType.DATA_BREACH,\n",
    "    affected_users_count=2500,\n",
    "    data_sensitivity=\"RESTRICTED\",\n",
    "    service_impact=\"PARTIAL\"\n",
    ")\n",
    "\n",
    "print(f\"Large data breach (2500 users, RESTRICTED data): {severity_p0}\")\n",
    "# Expected: P0_CRITICAL\n",
    "\n",
    "# Example 2: P1 Classification - Unauthorized access\n",
    "severity_p1 = IncidentClassifier.classify_incident(\n",
    "    incident_type=IncidentType.UNAUTHORIZED_ACCESS,\n",
    "    affected_users_count=150,\n",
    "    data_sensitivity=\"CONFIDENTIAL\",\n",
    "    service_impact=\"PARTIAL\"\n",
    ")\n",
    "\n",
    "print(f\"Unauthorized access (150 users): {severity_p1}\")\n",
    "# Expected: P1_HIGH\n",
    "\n",
    "# Example 3: P3 Classification - Low impact\n",
    "severity_p3 = IncidentClassifier.classify_incident(\n",
    "    incident_type=IncidentType.COMPLIANCE_FAILURE,\n",
    "    affected_users_count=3,\n",
    "    data_sensitivity=\"PUBLIC\",\n",
    "    service_impact=\"NONE\"\n",
    ")\n",
    "\n",
    "print(f\"Minor compliance issue (3 users, PUBLIC data): {severity_p3}\")\n",
    "# Expected: P3_LOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Breach Notification Requirements\n",
    "\n",
    "### When Notification is Required\n",
    "\n",
    "**GDPR (EU):**\n",
    "- Article 33: Notify Data Protection Authority within **72 hours** of becoming aware of breach\n",
    "- Article 34: Notify affected users if **high risk** to rights and freedoms\n",
    "- Penalties: Up to €20M or 4% of global annual revenue\n",
    "\n",
    "**DPDPA (India):**\n",
    "- Notify Data Protection Board within **reasonable time** (typically 72 hours)\n",
    "- Notify affected individuals\n",
    "- Penalties: Up to ₹250 crore\n",
    "\n",
    "**Key Decision Point:**\n",
    "Not all incidents require notification. Our classifier automatically determines this based on:\n",
    "1. Severity (all P0 incidents require notification)\n",
    "2. Incident type (DATA_BREACH and PII_EXPOSURE always require notification)\n",
    "3. Data sensitivity and user impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if notification is required\n",
    "\n",
    "# P0 incident - always requires notification\n",
    "notification_p0 = IncidentClassifier.requires_notification(\n",
    "    severity=IncidentSeverity.P0,\n",
    "    incident_type=IncidentType.SERVICE_OUTAGE\n",
    ")\n",
    "print(f\"P0 service outage requires notification: {notification_p0}\")\n",
    "# Expected: True\n",
    "\n",
    "# Data breach - always requires notification regardless of severity\n",
    "notification_breach = IncidentClassifier.requires_notification(\n",
    "    severity=IncidentSeverity.P2,\n",
    "    incident_type=IncidentType.DATA_BREACH\n",
    ")\n",
    "print(f\"P2 data breach requires notification: {notification_breach}\")\n",
    "# Expected: True\n",
    "\n",
    "# P3 non-breach - no notification required\n",
    "notification_p3 = IncidentClassifier.requires_notification(\n",
    "    severity=IncidentSeverity.P3,\n",
    "    incident_type=IncidentType.COMPLIANCE_FAILURE\n",
    ")\n",
    "print(f\"P3 compliance failure requires notification: {notification_p3}\")\n",
    "# Expected: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Phase 1 - Incident Detection\n",
    "\n",
    "### Detection Sources\n",
    "- **Automated monitoring:** SIEM alerts, anomaly detection, compliance scans\n",
    "- **User reports:** Security team escalations, customer complaints\n",
    "- **Audit findings:** Periodic security audits, penetration tests\n",
    "\n",
    "### What Happens During Detection\n",
    "1. Incident logged with unique ID\n",
    "2. Severity automatically classified\n",
    "3. Notification requirement determined\n",
    "4. If notification required, 72-hour deadline set\n",
    "5. Incident enters \"ACTIVE\" status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l3_m3_monitoring_reporting import IncidentResponseWorkflow\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Create workflow instance\n",
    "workflow = IncidentResponseWorkflow()\n",
    "\n",
    "# Detect a data breach incident\n",
    "incident = workflow.detect_incident(\n",
    "    tenant_id=\"tenant-healthcare-demo\",\n",
    "    incident_type=IncidentType.DATA_BREACH,\n",
    "    description=\"Unauthorized API access detected - customer PII exposed\",\n",
    "    detected_by=\"security-monitor\",\n",
    "    affected_users=[f\"user-{i}\" for i in range(1, 201)],  # 200 users\n",
    "    affected_data_types=[\"email\", \"phone_number\", \"address\"],\n",
    "    data_sensitivity=\"CONFIDENTIAL\",\n",
    "    service_impact=\"PARTIAL\"\n",
    ")\n",
    "\n",
    "print(f\"Incident ID: {incident.incident_id}\")\n",
    "print(f\"Severity: {incident.severity}\")\n",
    "print(f\"Notification required: {incident.notification_required}\")\n",
    "print(f\"Notification deadline: {incident.notification_deadline}\")\n",
    "print(f\"Current phase: {incident.current_phase}\")\n",
    "print(f\"Status: {incident.status}\")\n",
    "\n",
    "# Expected:\n",
    "# Incident ID: INC-tena-<hash>\n",
    "# Severity: P1_HIGH (200 users + CONFIDENTIAL data)\n",
    "# Notification required: True (data breach)\n",
    "# Notification deadline: ~72 hours from now\n",
    "# Current phase: detection\n",
    "# Status: ACTIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Phase 2 - Containment\n",
    "\n",
    "### Goal: Stop the Bleeding\n",
    "\n",
    "Containment prevents further damage while you investigate. Speed is critical - P0 incidents should be contained within 15 minutes.\n",
    "\n",
    "**Common Containment Actions:**\n",
    "- Disable compromised user accounts\n",
    "- Revoke API keys and access tokens\n",
    "- Block malicious IP addresses\n",
    "- Isolate affected tenant/database (multi-tenant)\n",
    "- Enable read-only mode on affected systems\n",
    "- Activate Web Application Firewall (WAF) rules\n",
    "\n",
    "**Trade-off:** Containment may cause service disruption for legitimate users. Balance speed with impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contain the incident\n",
    "containment_result = workflow.contain_incident(\n",
    "    incident_id=incident.incident_id,\n",
    "    containment_actions=[\n",
    "        \"Blocked IP address 203.0.113.45 (source of unauthorized access)\",\n",
    "        \"Revoked API key: ak_live_abc123def456\",\n",
    "        \"Disabled affected user accounts (200 users)\",\n",
    "        \"Enabled database read-only mode for tenant-healthcare-demo\",\n",
    "        \"Activated WAF rule: block-unauthorized-api-patterns\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Phase: {containment_result['phase']}\")\n",
    "print(f\"Status: {containment_result['status']}\")\n",
    "print(f\"Actions taken: {len(containment_result['actions_taken'])} actions\")\n",
    "print(f\"Timestamp: {containment_result['timestamp']}\")\n",
    "\n",
    "# Verify phase updated\n",
    "updated_incident = workflow.get_incident(incident.incident_id)\n",
    "print(f\"\\nIncident now in phase: {updated_incident.current_phase}\")\n",
    "\n",
    "# Expected:\n",
    "# Phase: containment\n",
    "# Status: contained\n",
    "# Actions taken: 5 actions\n",
    "# Incident now in phase: containment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Phase 3 - Investigation\n",
    "\n",
    "### Root Cause Analysis\n",
    "\n",
    "Investigation determines:\n",
    "1. **How did this happen?** (Attack vector, vulnerability exploited)\n",
    "2. **What was affected?** (Full scope of data/systems compromised)\n",
    "3. **Who was involved?** (Internal/external actors)\n",
    "4. **When did it start?** (Timeline of events)\n",
    "\n",
    "**Investigation Tasks:**\n",
    "- Analyze audit logs (from M3.3 - Audit Logging module)\n",
    "- Review SIEM correlation rules\n",
    "- Interview affected users and staff\n",
    "- Forensic analysis of affected systems\n",
    "- Timeline reconstruction\n",
    "\n",
    "**Output:** Detailed findings document for post-mortem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct investigation\n",
    "investigation_result = workflow.investigate_incident(\n",
    "    incident_id=incident.incident_id,\n",
    "    investigation_findings=\"\"\"\n",
    "    ROOT CAUSE: API authentication bypass vulnerability (CVE-2024-XXXXX)\n",
    "    \n",
    "    TIMELINE:\n",
    "    - 2025-11-16 08:00 UTC: Attacker discovered authentication bypass in /api/v2/users endpoint\n",
    "    - 2025-11-16 08:15 UTC: First unauthorized API call (GET /api/v2/users?limit=1000)\n",
    "    - 2025-11-16 08:15-09:45 UTC: 47 API calls extracting 200 user records\n",
    "    - 2025-11-16 09:50 UTC: SIEM alert triggered (unusual API pattern)\n",
    "    - 2025-11-16 10:00 UTC: Security team investigation started\n",
    "    \n",
    "    SCOPE:\n",
    "    - 200 user records accessed (email, phone, address)\n",
    "    - No payment data accessed (stored in separate database)\n",
    "    - No evidence of data exfiltration beyond API responses\n",
    "    \n",
    "    ATTACK VECTOR:\n",
    "    - Publicly disclosed vulnerability in authentication library v2.3.1\n",
    "    - Patch available (v2.3.2) but not yet deployed\n",
    "    - IP address 203.0.113.45 (Amsterdam, VPN)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(f\"Phase: {investigation_result['phase']}\")\n",
    "print(f\"Findings summary:\")\n",
    "print(investigation_result['findings'][:200] + \"...\")  # First 200 chars\n",
    "\n",
    "# Expected:\n",
    "# Phase: investigation\n",
    "# Findings: ROOT CAUSE: API authentication bypass vulnerability..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Phase 4 - Eradication\n",
    "\n",
    "### Removing the Threat\n",
    "\n",
    "Eradication eliminates the root cause so the incident can't recur.\n",
    "\n",
    "**Common Eradication Actions:**\n",
    "- **Patch vulnerabilities:** Apply security updates, upgrade libraries\n",
    "- **Remove malware:** Clean infected systems, rebuild compromised servers\n",
    "- **Reset credentials:** Force password resets, rotate all secrets\n",
    "- **Update policies:** Fix RBAC misconfigurations, tighten access controls\n",
    "- **Harden systems:** Enable additional security features (2FA, WAF, rate limiting)\n",
    "\n",
    "**Validation:** Test that the vulnerability is actually fixed before recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eradicate the threat\n",
    "eradication_result = workflow.eradicate_threat(\n",
    "    incident_id=incident.incident_id,\n",
    "    eradication_actions=[\n",
    "        \"Upgraded authentication library from v2.3.1 to v2.3.2 (patched vulnerability)\",\n",
    "        \"Deployed patch to production (3 API servers)\",\n",
    "        \"Rotated all API keys (1,234 keys invalidated, new keys issued)\",\n",
    "        \"Implemented rate limiting: 100 requests/minute per API key\",\n",
    "        \"Added input validation to /api/v2/users endpoint\",\n",
    "        \"Enabled API request logging for all /api/v2/* endpoints\",\n",
    "        \"Verified vulnerability no longer exploitable via penetration test\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Phase: {eradication_result['phase']}\")\n",
    "print(f\"Actions taken: {len(eradication_result['actions_taken'])} eradication actions\")\n",
    "print(\"\\nKey actions:\")\n",
    "for i, action in enumerate(eradication_result['actions_taken'][:3], 1):\n",
    "    print(f\"  {i}. {action[:80]}...\")  # First 80 chars\n",
    "\n",
    "# Expected:\n",
    "# Phase: eradication\n",
    "# Actions taken: 7 eradication actions\n",
    "# Key actions:\n",
    "#   1. Upgraded authentication library from v2.3.1 to v2.3.2...\n",
    "#   2. Deployed patch to production (3 API servers)...\n",
    "#   3. Rotated all API keys (1,234 keys invalidated, new keys issued)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Phase 5 - Recovery\n",
    "\n",
    "### Restoring Normal Operations\n",
    "\n",
    "Recovery brings systems back online after eradication is complete.\n",
    "\n",
    "**Recovery Steps:**\n",
    "1. **Re-enable services:** Disable read-only mode, restore write access\n",
    "2. **Restore user access:** Re-enable accounts (with new credentials)\n",
    "3. **Verify integrity:** Ensure no lingering compromise\n",
    "4. **Monitor closely:** Watch for signs of recurrence (24-48 hours)\n",
    "5. **Communicate:** Notify users that service is restored\n",
    "\n",
    "**Validation Checklist:**\n",
    "- [ ] All systems operational\n",
    "- [ ] All security patches applied\n",
    "- [ ] Monitoring in place for recurrence\n",
    "- [ ] Users notified of service restoration\n",
    "- [ ] SLA compliance verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover services\n",
    "recovery_result = workflow.recover_services(\n",
    "    incident_id=incident.incident_id,\n",
    "    recovery_steps=[\n",
    "        \"Disabled read-only mode for tenant-healthcare-demo database\",\n",
    "        \"Re-enabled API access with new rate limits\",\n",
    "        \"Re-enabled 200 affected user accounts (new API keys issued)\",\n",
    "        \"Sent email to affected users: 'Service restored, please use new API key'\",\n",
    "        \"Verified all API endpoints responding normally (200 OK)\",\n",
    "        \"Enabled enhanced monitoring: alert if >50 API calls/min from single IP\",\n",
    "        \"Scheduled 24-hour incident watch (security team on-call)\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Phase: {recovery_result['phase']}\")\n",
    "print(f\"Recovery steps completed: {len(recovery_result['recovery_steps'])}\")\n",
    "print(f\"Timestamp: {recovery_result['timestamp']}\")\n",
    "\n",
    "# Verify incident is in recovery phase\n",
    "updated_incident = workflow.get_incident(incident.incident_id)\n",
    "print(f\"\\nIncident status: {updated_incident.status}\")\n",
    "print(f\"Current phase: {updated_incident.current_phase}\")\n",
    "\n",
    "# Expected:\n",
    "# Phase: recovery\n",
    "# Recovery steps completed: 7\n",
    "# Incident status: ACTIVE (still open, awaiting post-mortem)\n",
    "# Current phase: recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Phase 6 - Post-Mortem and Closure\n",
    "\n",
    "### Learning from Incidents\n",
    "\n",
    "Post-mortem documents what happened and ensures it doesn't happen again.\n",
    "\n",
    "**Post-Mortem Contents:**\n",
    "1. **Timeline:** Complete sequence of events from detection to resolution\n",
    "2. **Root cause:** Why the incident occurred (technical + process failures)\n",
    "3. **Lessons learned:** What went well, what didn't\n",
    "4. **Preventive measures:** Specific actions to prevent recurrence\n",
    "5. **Process improvements:** Updates to incident response runbooks\n",
    "\n",
    "**Key Principle: Blameless Post-Mortems**\n",
    "- Focus on systems, not individuals\n",
    "- Goal: Improve processes, not punish people\n",
    "- Create psychological safety for honest reporting\n",
    "\n",
    "**After Post-Mortem:**\n",
    "- Incident status changes from \"ACTIVE\" to \"CLOSED\"\n",
    "- Resolution time recorded\n",
    "- Preventive measures tracked to completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close incident with post-mortem\n",
    "postmortem_result = workflow.close_with_post_mortem(\n",
    "    incident_id=incident.incident_id,\n",
    "    lessons_learned=\"\"\"\n",
    "    WHAT WENT WELL:\n",
    "    - SIEM detected unusual API pattern within 1 hour 35 minutes\n",
    "    - Containment completed within 15 minutes of detection\n",
    "    - Multi-tenant isolation prevented other tenants from being affected\n",
    "    - Security patch available and deployed within 4 hours\n",
    "    \n",
    "    WHAT DIDN'T GO WELL:\n",
    "    - Authentication library vulnerability was publicly disclosed 2 weeks ago\n",
    "    - Patch (v2.3.2) was available but not deployed (missed in sprint planning)\n",
    "    - No automated dependency scanning in CI/CD pipeline\n",
    "    - API rate limiting was not enabled (could have slowed attacker)\n",
    "    \n",
    "    ROOT CAUSE ANALYSIS:\n",
    "    Technical: CVE-2024-XXXXX in auth library v2.3.1 (known vulnerability)\n",
    "    Process: No automated patch management for critical dependencies\n",
    "    \n",
    "    IMPACT:\n",
    "    - 200 users affected (PII exposed)\n",
    "    - 1 hour 45 minutes of service disruption (read-only mode)\n",
    "    - Estimated cost: $15K (incident response time + user notifications)\n",
    "    - GDPR notification required (breach reported to DPA)\n",
    "    \"\"\",\n",
    "    preventive_measures=[\n",
    "        \"Implement automated dependency scanning (Dependabot, Snyk) in CI/CD\",\n",
    "        \"Create weekly security patch review process (every Monday)\",\n",
    "        \"Enable API rate limiting by default: 100 req/min per key\",\n",
    "        \"Add SIEM alert: notify if critical CVE affects our stack within 24 hours\",\n",
    "        \"Conduct quarterly incident response drills (tabletop exercises)\",\n",
    "        \"Update runbook: authentication vulnerabilities are P0 for patching\",\n",
    "        \"Schedule penetration test: focus on API authentication bypass scenarios\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Phase: {postmortem_result['phase']}\")\n",
    "print(f\"Detected at: {postmortem_result['detected_at']}\")\n",
    "print(f\"Resolved at: {postmortem_result['resolved_at']}\")\n",
    "print(f\"Total duration: {postmortem_result['duration']}\")\n",
    "print(f\"\\nPreventive measures: {len(postmortem_result['preventive_measures'])} actions\")\n",
    "\n",
    "# Verify incident is closed\n",
    "final_incident = workflow.get_incident(incident.incident_id)\n",
    "print(f\"\\nFinal status: {final_incident.status}\")\n",
    "print(f\"Final phase: {final_incident.current_phase}\")\n",
    "\n",
    "# Expected:\n",
    "# Phase: post_mortem\n",
    "# Total duration: ~few seconds (in demo)\n",
    "# Preventive measures: 7 actions\n",
    "# Final status: CLOSED\n",
    "# Final phase: post_mortem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Breach Notification Automation\n",
    "\n",
    "### GDPR Article 33 - Regulatory Notification\n",
    "\n",
    "When a data breach requires notification (P0/P1 data breaches), you must notify the Data Protection Authority within 72 hours.\n",
    "\n",
    "**Required Information:**\n",
    "1. Nature of the breach (what happened)\n",
    "2. Categories of data subjects affected (users, customers, employees)\n",
    "3. Approximate number of affected individuals\n",
    "4. Data categories involved (email, phone, financial, health)\n",
    "5. Likely consequences of the breach\n",
    "6. Measures taken to address the breach\n",
    "7. Contact point for more information\n",
    "\n",
    "**Automation Benefits:**\n",
    "- Ensures notification sent within deadline\n",
    "- Standardized notification format\n",
    "- Automatic inclusion of all required fields\n",
    "- Proof of timely notification (audit trail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send GDPR breach notification to DPA\n",
    "gdpr_notification = workflow.send_breach_notification(\n",
    "    incident_id=incident.incident_id,\n",
    "    recipient=\"dpa@example.eu\",\n",
    "    notification_type=\"REGULATORY\",\n",
    "    regulation=\"GDPR\"\n",
    ")\n",
    "\n",
    "print(f\"Notification ID: {gdpr_notification.notification_id}\")\n",
    "print(f\"Sent to: {gdpr_notification.recipient}\")\n",
    "print(f\"Notification type: {gdpr_notification.notification_type}\")\n",
    "print(f\"Regulation: {gdpr_notification.regulation}\")\n",
    "print(f\"Sent at: {gdpr_notification.sent_at}\")\n",
    "print(f\"\\nNotification content (preview):\")\n",
    "print(gdpr_notification.notification_content[:300] + \"...\")  # First 300 chars\n",
    "\n",
    "# Expected:\n",
    "# Notification ID: NOT-<hash>\n",
    "# Sent to: dpa@example.eu\n",
    "# Notification type: REGULATORY\n",
    "# Regulation: GDPR\n",
    "# Content includes: GDPR Article 33, incident details, affected users, data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPDPA - India Breach Notification\n",
    "\n",
    "Similar to GDPR, India's Digital Personal Data Protection Act (DPDPA) requires notification to the Data Protection Board of India."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send DPDPA breach notification\n",
    "dpdpa_notification = workflow.send_breach_notification(\n",
    "    incident_id=incident.incident_id,\n",
    "    recipient=\"dpb@india.gov\",\n",
    "    notification_type=\"REGULATORY\",\n",
    "    regulation=\"DPDPA\"\n",
    ")\n",
    "\n",
    "print(f\"DPDPA Notification sent to: {dpdpa_notification.recipient}\")\n",
    "print(f\"Regulation: {dpdpa_notification.regulation}\")\n",
    "print(f\"\\nNotification content (preview):\")\n",
    "print(dpdpa_notification.notification_content[:250] + \"...\")  # First 250 chars\n",
    "\n",
    "# Expected:\n",
    "# Notification includes: DPDPA reference, incident details, affected individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Notification (GDPR Article 34)\n",
    "\n",
    "If the breach poses a **high risk** to individuals' rights and freedoms, you must also notify affected users directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send user notification\n",
    "user_notification = workflow.send_breach_notification(\n",
    "    incident_id=incident.incident_id,\n",
    "    recipient=\"affected.users@example.com\",\n",
    "    notification_type=\"USER\",\n",
    "    regulation=\"GDPR\"\n",
    ")\n",
    "\n",
    "print(f\"User notification sent to: {user_notification.recipient}\")\n",
    "print(f\"Notification type: {user_notification.notification_type}\")\n",
    "\n",
    "# List all notifications for this incident\n",
    "all_notifications = workflow.notifications\n",
    "incident_notifications = [n for n in all_notifications if n.incident_id == incident.incident_id]\n",
    "\n",
    "print(f\"\\nTotal notifications sent for {incident.incident_id}: {len(incident_notifications)}\")\n",
    "for notif in incident_notifications:\n",
    "    print(f\"  - {notif.notification_type}: {notif.recipient} ({notif.regulation})\")\n",
    "\n",
    "# Expected:\n",
    "# Total notifications: 3 (DPA GDPR, DPA DPDPA, User)\n",
    "#   - REGULATORY: dpa@example.eu (GDPR)\n",
    "#   - REGULATORY: dpb@india.gov (DPDPA)\n",
    "#   - USER: affected.users@example.com (GDPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10: Multi-Tenant Incident Isolation\n",
    "\n",
    "### Why Multi-Tenant Isolation Matters\n",
    "\n",
    "In GCC environments, you manage incidents for multiple customers (tenants). Critical requirements:\n",
    "1. **Data isolation:** Tenant A can't see Tenant B's incidents\n",
    "2. **Independent workflows:** Each tenant's incidents are tracked separately\n",
    "3. **Separate notifications:** Breach in Tenant A doesn't trigger notification for Tenant B\n",
    "\n",
    "### Implementation\n",
    "Every incident is tagged with `tenant_id`. All queries filter by tenant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create incidents for different tenants\n",
    "\n",
    "# Tenant A: Healthcare company (P0 incident)\n",
    "incident_a = workflow.detect_incident(\n",
    "    tenant_id=\"tenant-healthcare-a\",\n",
    "    incident_type=IncidentType.DATA_BREACH,\n",
    "    description=\"HIPAA violation - patient records exposed\",\n",
    "    detected_by=\"compliance-scan\",\n",
    "    affected_users=[f\"patient-{i}\" for i in range(1000)],\n",
    "    affected_data_types=[\"health_records\", \"ssn\"],\n",
    "    data_sensitivity=\"RESTRICTED\",\n",
    "    service_impact=\"PARTIAL\"\n",
    ")\n",
    "\n",
    "# Tenant B: E-commerce company (P3 incident)\n",
    "incident_b = workflow.detect_incident(\n",
    "    tenant_id=\"tenant-ecommerce-b\",\n",
    "    incident_type=IncidentType.COMPLIANCE_FAILURE,\n",
    "    description=\"Cookie consent banner missing on checkout page\",\n",
    "    detected_by=\"automated-test\",\n",
    "    affected_users=[f\"customer-{i}\" for i in range(5)],\n",
    "    affected_data_types=[\"cookie_preferences\"],\n",
    "    data_sensitivity=\"PUBLIC\",\n",
    "    service_impact=\"NONE\"\n",
    ")\n",
    "\n",
    "# Tenant C: Financial services (P1 incident)\n",
    "incident_c = workflow.detect_incident(\n",
    "    tenant_id=\"tenant-fintech-c\",\n",
    "    incident_type=IncidentType.UNAUTHORIZED_ACCESS,\n",
    "    description=\"Failed brute force attack on admin panel\",\n",
    "    detected_by=\"security-monitor\",\n",
    "    affected_users=[f\"admin-{i}\" for i in range(3)],\n",
    "    affected_data_types=[\"login_credentials\"],\n",
    "    data_sensitivity=\"CONFIDENTIAL\",\n",
    "    service_impact=\"NONE\"\n",
    ")\n",
    "\n",
    "print(f\"Tenant A incident: {incident_a.incident_id} - {incident_a.severity}\")\n",
    "print(f\"Tenant B incident: {incident_b.incident_id} - {incident_b.severity}\")\n",
    "print(f\"Tenant C incident: {incident_c.incident_id} - {incident_c.severity}\")\n",
    "\n",
    "# Expected:\n",
    "# Tenant A: P0_CRITICAL (1000 users, RESTRICTED health data)\n",
    "# Tenant B: P3_LOW (5 users, PUBLIC data)\n",
    "# Tenant C: P1_HIGH (unauthorized access, CONFIDENTIAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query incidents by tenant - demonstrate isolation\n",
    "\n",
    "# Tenant A incidents only\n",
    "tenant_a_incidents = workflow.list_incidents(tenant_id=\"tenant-healthcare-a\")\n",
    "print(f\"Tenant A incidents: {len(tenant_a_incidents)}\")\n",
    "for inc in tenant_a_incidents:\n",
    "    print(f\"  - {inc.incident_id}: {inc.description[:50]}...\")\n",
    "\n",
    "# Tenant B incidents only\n",
    "tenant_b_incidents = workflow.list_incidents(tenant_id=\"tenant-ecommerce-b\")\n",
    "print(f\"\\nTenant B incidents: {len(tenant_b_incidents)}\")\n",
    "for inc in tenant_b_incidents:\n",
    "    print(f\"  - {inc.incident_id}: {inc.description[:50]}...\")\n",
    "\n",
    "# All P0 incidents across all tenants (admin view)\n",
    "p0_incidents = workflow.list_incidents(severity=IncidentSeverity.P0)\n",
    "print(f\"\\nAll P0 incidents (admin view): {len(p0_incidents)}\")\n",
    "for inc in p0_incidents:\n",
    "    print(f\"  - {inc.incident_id} ({inc.tenant_id}): {inc.description[:40]}...\")\n",
    "\n",
    "# Expected:\n",
    "# Tenant A: 1 incident (healthcare breach)\n",
    "# Tenant B: 1 incident (cookie compliance)\n",
    "# P0 incidents: 1-2 incidents (depends on earlier examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 11: Production Best Practices\n",
    "\n",
    "### Incident Response Readiness\n",
    "\n",
    "**Before Production:**\n",
    "1. **Test the workflow:** Run incident response drills (tabletop exercises)\n",
    "2. **Train the team:** Everyone knows their role in P0 incidents\n",
    "3. **Set up integrations:** SIEM alerts → automated incident detection\n",
    "4. **Define escalation paths:** P0 → page CEO, P1 → page security team, etc.\n",
    "5. **Prepare notification templates:** Pre-approved by legal team\n",
    "\n",
    "**During Incident:**\n",
    "1. **Stay calm:** Follow the 6-phase workflow\n",
    "2. **Document everything:** Every action logged with timestamp\n",
    "3. **Communicate proactively:** Update stakeholders every hour for P0\n",
    "4. **Don't skip phases:** Even if under pressure\n",
    "\n",
    "**After Incident:**\n",
    "1. **Complete post-mortem:** Within 48 hours of resolution\n",
    "2. **Track preventive measures:** Assign owners, set deadlines\n",
    "3. **Update runbooks:** Incorporate lessons learned\n",
    "4. **Share knowledge:** Present post-mortem to engineering team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production readiness check\n",
    "\n",
    "# Count active incidents by severity\n",
    "active_incidents = workflow.list_incidents(status=\"ACTIVE\")\n",
    "p0_active = [i for i in active_incidents if i.severity == IncidentSeverity.P0]\n",
    "p1_active = [i for i in active_incidents if i.severity == IncidentSeverity.P1]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"INCIDENT RESPONSE DASHBOARD\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total incidents tracked: {len(workflow.incidents)}\")\n",
    "print(f\"Active incidents: {len(active_incidents)}\")\n",
    "print(f\"  - P0 (Critical): {len(p0_active)}\")\n",
    "print(f\"  - P1 (High): {len(p1_active)}\")\n",
    "print(f\"\\nClosed incidents: {len(workflow.list_incidents(status='CLOSED'))}\")\n",
    "print(f\"Total notifications sent: {len(workflow.notifications)}\")\n",
    "\n",
    "# Check for pending notifications (deadline approaching)\n",
    "pending_notifications = [\n",
    "    i for i in workflow.incidents.values()\n",
    "    if i.notification_required and i.notification_deadline and i.status == \"ACTIVE\"\n",
    "]\n",
    "\n",
    "if pending_notifications:\n",
    "    print(f\"\\n⚠️ WARNING: {len(pending_notifications)} incidents require notification:\")\n",
    "    for inc in pending_notifications:\n",
    "        print(f\"  - {inc.incident_id}: Deadline {inc.notification_deadline}\")\n",
    "else:\n",
    "    print(\"\\n✓ No pending notifications\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Expected output will vary based on incidents created in this session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 12: Compliance Checklist\n",
    "\n",
    "### Regulatory Requirements Covered\n",
    "\n",
    "**GDPR (EU):**\n",
    "- ✓ Article 33: DPA notification within 72 hours\n",
    "- ✓ Article 34: User notification if high risk\n",
    "- ✓ Article 32: Security incident response procedures\n",
    "- ✓ Article 5: Accountability (documented incident handling)\n",
    "\n",
    "**DPDPA (India):**\n",
    "- ✓ Section 6: Data breach notification to Data Protection Board\n",
    "- ✓ Section 8: Notification to data principals (users)\n",
    "- ✓ Reasonable security practices (incident response workflow)\n",
    "\n",
    "**SOC 2 (Trust Services Criteria):**\n",
    "- ✓ CC7.3: Security incident detection and response\n",
    "- ✓ CC7.4: Incident response plan\n",
    "- ✓ CC9.1: Risk mitigation activities\n",
    "\n",
    "**ISO 27001:**\n",
    "- ✓ A.16: Information security incident management\n",
    "- ✓ A.16.1.4: Assessment and decision on information security events\n",
    "- ✓ A.16.1.5: Response to information security incidents\n",
    "- ✓ A.16.1.7: Collection of evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've built a production-ready incident response system that:\n",
    "\n",
    "1. **Classifies incidents** automatically (P0-P3) based on impact\n",
    "2. **Enforces 6-phase workflow** from detection to post-mortem\n",
    "3. **Automates breach notifications** for GDPR and DPDPA compliance\n",
    "4. **Isolates multi-tenant incidents** for GCC environments\n",
    "5. **Tracks regulatory deadlines** (72-hour GDPR notification)\n",
    "6. **Documents everything** for audit trail and compliance\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Integrate with SIEM:** Connect your monitoring (M3.3) to automated incident detection\n",
    "2. **Customize thresholds:** Adjust P0/P1/P2/P3 criteria for your risk tolerance\n",
    "3. **Add notification integrations:** Email/SMS for user notifications, PagerDuty for P0 alerts\n",
    "4. **Run drills:** Practice incident response with tabletop exercises\n",
    "5. **Deploy to production:** Start with non-critical tenants, gradually expand\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Speed matters:** P0 containment in <15 minutes prevents damage\n",
    "- **Don't skip phases:** Investigation before eradication (understand root cause first)\n",
    "- **Documentation is insurance:** Post-mortems protect you in audits\n",
    "- **Automation reduces errors:** Manual notification = missed deadlines\n",
    "- **Multi-tenant isolation is critical:** Never leak one tenant's incident to another\n",
    "\n",
    "You're now ready to handle security incidents and breach notifications in production GCC RAG systems!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
