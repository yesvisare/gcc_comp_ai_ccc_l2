{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L3 M4.1: Model Cards & AI Governance\n",
    "\n",
    "## Learning Arc\n",
    "\n",
    "**Purpose:** Implement comprehensive AI governance for RAG systems through model card documentation, statistical bias detection, human-in-the-loop workflows, and governance committee oversight - aligned with NIST AI RMF and EU AI Act requirements.\n",
    "\n",
    "**Concepts Covered:**\n",
    "- Three-pillar AI governance framework (Fairness, Transparency, Accountability)\n",
    "- NIST AI Risk Management Framework (Govern, Map, Measure, Manage)\n",
    "- EU AI Act risk classification and high-risk system requirements\n",
    "- 10-section model card documentation standard\n",
    "- Statistical bias detection with demographic parity testing\n",
    "- Human-in-the-loop workflows for high-stakes queries\n",
    "- Governance committee review processes with voting and approval thresholds\n",
    "- Incident tracking and severity-based escalation\n",
    "- Regulatory compliance (GDPR, DPDPA, SOX, EU AI Act)\n",
    "- Cost-benefit analysis for GCC governance investment\n",
    "\n",
    "**After Completing This Notebook:**\n",
    "- You will understand AI governance principles and regulatory requirements (NIST AI RMF, EU AI Act)\n",
    "- You can create comprehensive model cards documenting all 10 required sections\n",
    "- You can implement statistical bias detection to identify unfair treatment across demographics\n",
    "- You will recognize when queries require human review (legal, HR, financial decisions)\n",
    "- You can establish governance committee processes with approval workflows\n",
    "- You will know how to track and escalate AI system incidents by severity\n",
    "- You can justify governance investment costs through regulatory risk analysis\n",
    "\n",
    "**Context in Track L3.M4:**\n",
    "This module builds on L3 M1-M3 (RAG fundamentals, evaluation, compliance) and prepares you for L3 M4.2 (Security & Privacy Controls). It shifts focus from technical implementation to organizational governance and regulatory compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Environment Setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add src to path for imports\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.insert(0, '../src')\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')\n",
    "\n",
    "# This module runs entirely LOCAL/OFFLINE\n",
    "# No external AI service APIs required (OpenAI, Anthropic, Pinecone, etc.)\n",
    "# Uses only local Python libraries: json, pandas, scipy\n",
    "\n",
    "print(\"✓ L3 M4.1: Model Cards & AI Governance\")\n",
    "print(\"✓ SERVICE: LOCAL (offline operation)\")\n",
    "print(\"✓ No external API keys required\")\n",
    "print(\"✓ Core features: Model cards, bias detection, governance workflows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: AI Governance Principles\n",
    "\n",
    "### The Three Pillars of Responsible AI\n",
    "\n",
    "**Fairness:** Ensuring your AI system does not discriminate or produce biased outcomes\n",
    "- Test whether different user groups receive similar quality results\n",
    "- Measure demographic parity across regions, departments, languages\n",
    "- Set thresholds (e.g., <10% disparity acceptable)\n",
    "\n",
    "**Transparency:** Making decisions explainable with source documentation\n",
    "- Model cards document components, data sources, limitations\n",
    "- Audit logs enable query traceability\n",
    "- Users can see which documents were retrieved and why\n",
    "\n",
    "**Accountability:** Clear ownership and oversight mechanisms\n",
    "- Governance committee with decision authority\n",
    "- Formal approval workflows for changes\n",
    "- Incident escalation with severity-based SLAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: NIST AI Risk Management Framework\n",
    "\n",
    "Four core functions for managing AI risks:\n",
    "\n",
    "**1. GOVERN** - Establish policies and organizational structures\n",
    "- Form governance committee (Security, Legal, Privacy, Product, Engineering)\n",
    "- Define review cadence (quarterly)\n",
    "- Set approval thresholds (75% for major changes)\n",
    "\n",
    "**2. MAP** - Identify and assess AI-specific risks\n",
    "- Document data sources and preprocessing\n",
    "- Identify potential bias sources (data, retrieval, generation)\n",
    "- Map high-stakes use cases requiring human review\n",
    "\n",
    "**3. MEASURE** - Track metrics and performance testing\n",
    "- Run bias tests across demographics\n",
    "- Monitor retrieval quality by user group\n",
    "- Track incident frequency and severity\n",
    "\n",
    "**4. MANAGE** - Mitigate risks and respond to incidents\n",
    "- Human-in-the-loop for high-risk queries\n",
    "- Incident escalation based on severity\n",
    "- Remediation tracking with owners and deadlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: EU AI Act Risk Classification\n",
    "\n",
    "### Risk Levels and Requirements\n",
    "\n",
    "**Unacceptable Risk** (BANNED):\n",
    "- Social scoring systems\n",
    "- Real-time biometric surveillance in public spaces\n",
    "- Manipulation of vulnerable groups\n",
    "\n",
    "**High Risk** (REGULATED) ← RAG systems often fall here:\n",
    "- HR decisions (hiring, termination, promotions)\n",
    "- Legal systems (case research, contract analysis)\n",
    "- Credit scoring and financial decisions\n",
    "\n",
    "**Requirements for High-Risk Systems:**\n",
    "- ✓ Model card documentation\n",
    "- ✓ Bias assessment and testing\n",
    "- ✓ Human oversight capabilities\n",
    "- ✓ Audit trail logging\n",
    "\n",
    "**Limited Risk** (TRANSPARENCY REQUIRED):\n",
    "- Chatbots must disclose they are AI\n",
    "- Deepfakes must be labeled\n",
    "\n",
    "**Minimal Risk** (NO REGULATION):\n",
    "- Most informational queries\n",
    "- Low-stakes applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import Governance Classes\n",
    "from l3_m4_enterprise_integration import (\n",
    "    RAGModelCard,\n",
    "    BiasDetector,\n",
    "    HumanInTheLoopWorkflow,\n",
    "    GovernanceReviewer\n",
    ")\n",
    "import json\n",
    "\n",
    "print(\"✓ Imported all governance classes\")\n",
    "print(\"  - RAGModelCard: 10-section model card generation\")\n",
    "print(\"  - BiasDetector: Statistical demographic parity testing\")\n",
    "print(\"  - HumanInTheLoopWorkflow: High-stakes query routing\")\n",
    "print(\"  - GovernanceReviewer: Committee voting and incident tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Model Card Generation\n",
    "\n",
    "### The 10-Section Standard\n",
    "\n",
    "Model cards are standardized documentation for AI systems - like nutrition labels for food.\n",
    "\n",
    "**10 Required Sections:**\n",
    "1. **Model Details:** Identity, version, owner, contact\n",
    "2. **Components:** Embedding model, vector DB, LLM, retrieval method\n",
    "3. **Intended Use:** Primary use cases + **out-of-scope uses** (liability protection)\n",
    "4. **Training & Data:** Sources, volume, preprocessing, gaps\n",
    "5. **Performance:** Metrics with baselines (precision@5, recall@10)\n",
    "6. **Ethical Considerations:** Fairness testing, bias mitigation, privacy\n",
    "7. **Limitations:** Known failure modes and edge cases\n",
    "8. **Recommendations:** Usage guidelines and monitoring\n",
    "9. **Governance:** Committee structure, review cadence, escalation\n",
    "10. **Change Log:** Version history with timestamps\n",
    "\n",
    "**Critical Insight:** \"Out-of-scope uses protect from liability\" - Explicitly documenting prohibited applications defends against misuse claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Create a Model Card\n",
    "card = RAGModelCard(\n",
    "    model_name=\"GCC_Compliance_RAG\",\n",
    "    model_version=\"1.0.0\",\n",
    "    model_owner=\"AI Engineering Team\",\n",
    "    contact_email=\"ai-engineering@gcc.com\"\n",
    ")\n",
    "\n",
    "# Document RAG components\n",
    "card.set_components(\n",
    "    embedding_model=\"text-embedding-3-small\",\n",
    "    vector_database=\"Qdrant\",\n",
    "    generation_model=\"gpt-4\",\n",
    "    retrieval_method=\"hybrid (semantic + keyword)\",\n",
    "    reranker=\"cohere-rerank-v3\"\n",
    ")\n",
    "\n",
    "# Define intended and prohibited uses\n",
    "card.set_intended_use(\n",
    "    primary_use_cases=[\n",
    "        \"Employee HR policy questions\",\n",
    "        \"Compliance document retrieval for legal team\",\n",
    "        \"Benefits information lookup\"\n",
    "    ],\n",
    "    out_of_scope_uses=[\n",
    "        \"Making hiring/firing decisions without human review\",\n",
    "        \"Providing legal advice for lawsuits\",\n",
    "        \"Setting employee compensation\",\n",
    "        \"Medical diagnosis or treatment recommendations\"\n",
    "    ],\n",
    "    target_users=[\"HR team\", \"Legal team\", \"Employees\"],\n",
    "    use_limitations=[\"Requires human review for high-stakes decisions\"]\n",
    ")\n",
    "\n",
    "# Add limitations\n",
    "card.add_limitation(\"May hallucinate when document coverage is sparse\")\n",
    "card.add_limitation(\"Retrieval quality degrades with ambiguous queries\")\n",
    "card.add_limitation(\"Does not handle multi-lingual queries equally well\")\n",
    "\n",
    "# Add recommendations\n",
    "card.add_recommendation(\"Conduct quarterly bias testing across user demographics\")\n",
    "card.add_recommendation(\"Route legal/HR/financial queries to human review\")\n",
    "card.add_recommendation(\"Monitor retrieval quality by region and department\")\n",
    "\n",
    "# Set governance\n",
    "card.set_governance(\n",
    "    review_committee=[\"Security\", \"Legal\", \"Privacy\", \"Product\", \"Engineering\"],\n",
    "    review_cadence=\"Quarterly\",\n",
    "    incident_escalation=\"Report via JIRA to AI Governance Board\",\n",
    "    approval_authority=\"VP Engineering and Chief Legal Officer\"\n",
    ")\n",
    "\n",
    "# Add change log\n",
    "card.add_change_log_entry(\n",
    "    version=\"1.0.0\",\n",
    "    changes=\"Initial release with GPT-4 and hybrid search\",\n",
    "    author=\"AI Engineering Team\"\n",
    ")\n",
    "\n",
    "print(\"✓ Model card created with 10 sections\")\n",
    "print(f\"  Name: {card.model_name}\")\n",
    "print(f\"  Version: {card.model_version}\")\n",
    "print(f\"  Primary uses: {len(card.intended_use.get('primary_use_cases', []))}\")\n",
    "print(f\"  Out-of-scope uses: {len(card.intended_use.get('out_of_scope_uses', []))}\")\n",
    "print(f\"  Limitations: {len(card.limitations)}\")\n",
    "print(f\"  Recommendations: {len(card.recommendations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Export Model Card as JSON\n",
    "json_output = card.to_json()\n",
    "parsed = json.loads(json_output)\n",
    "\n",
    "print(\"✓ Model card exported to JSON\")\n",
    "print(f\"\\nTop-level keys: {list(parsed.keys())}\")\n",
    "print(f\"\\nModel Details:\")\n",
    "print(f\"  {parsed['model_details']}\")\n",
    "print(f\"\\nComponents:\")\n",
    "for key, value in parsed['components'].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Expected: JSON with all 10 sections populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Export Model Card as Markdown\n",
    "markdown_output = card.to_markdown()\n",
    "\n",
    "print(\"✓ Model card exported to Markdown\")\n",
    "print(f\"\\nFirst 500 characters:\")\n",
    "print(markdown_output[:500])\n",
    "print(\"\\n...\")\n",
    "\n",
    "# Uncomment to see full markdown\n",
    "# print(markdown_output)\n",
    "\n",
    "# Expected: Markdown document with all 10 sections formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVED_SECTION:1** (Model Card Generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Bias Detection Framework\n",
    "\n",
    "### Three Categories of Bias in RAG Systems\n",
    "\n",
    "**1. Data Bias:** Training collection over-represents certain groups\n",
    "- Example: 80% North America docs, 20% Asia-Pacific → NA queries get better results\n",
    "- Mitigation: Balanced data collection, stratified sampling\n",
    "\n",
    "**2. Retrieval Bias:** Semantic search favors particular document types\n",
    "- Example: Technical docs rank higher than policy docs for all queries\n",
    "- Mitigation: Hybrid search (semantic + keyword), reranking\n",
    "\n",
    "**3. Generation Bias:** LLM training data imbalances\n",
    "- Example: Stereotyped outputs (engineers assumed male, nurses assumed female)\n",
    "- Mitigation: Fine-tuning, output filters, human review\n",
    "\n",
    "### Statistical Testing Approach\n",
    "\n",
    "**Demographic Parity:** Do different groups receive similar quality?\n",
    "- Compare average scores across groups (Region A vs Region B)\n",
    "- Flag if disparity >10% (configurable threshold)\n",
    "- Use pandas and scipy for statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Initialize Bias Detector\n",
    "detector = BiasDetector(disparity_threshold=0.10)  # 10% threshold\n",
    "\n",
    "print(\"✓ BiasDetector initialized\")\n",
    "print(f\"  Disparity threshold: {detector.disparity_threshold * 100}%\")\n",
    "print(f\"  Interpretation: Flag if quality difference between groups > 10%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Test Case 1 - No Bias Detected\n",
    "# Scenario: Both regions get similar quality results\n",
    "\n",
    "north_america_scores = [0.88, 0.90, 0.87, 0.89, 0.91, 0.88, 0.90]\n",
    "asia_pacific_scores = [0.85, 0.87, 0.86, 0.84, 0.88, 0.85, 0.87]\n",
    "\n",
    "result = detector.test_demographic_parity(\n",
    "    group_a_scores=north_america_scores,\n",
    "    group_b_scores=asia_pacific_scores,\n",
    "    group_a_name=\"North America\",\n",
    "    group_b_name=\"Asia Pacific\"\n",
    ")\n",
    "\n",
    "print(\"Test Case 1: Regional Quality Comparison\")\n",
    "print(f\"  North America avg: {result['group_a']['avg_score']}\")\n",
    "print(f\"  Asia Pacific avg: {result['group_b']['avg_score']}\")\n",
    "print(f\"  Relative disparity: {result['disparity']['relative'] * 100:.1f}%\")\n",
    "print(f\"  Bias detected: {result['bias_detected']}\")\n",
    "print(f\"  Severity: {result['severity']}\")\n",
    "\n",
    "# Expected: bias_detected = False (disparity < 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Test Case 2 - Bias Detected (Medium Severity)\n",
    "# Scenario: Engineering gets much better results than Marketing\n",
    "\n",
    "engineering_scores = [0.92, 0.94, 0.91, 0.93, 0.92, 0.94, 0.93]\n",
    "marketing_scores = [0.75, 0.73, 0.76, 0.74, 0.77, 0.75, 0.76]\n",
    "\n",
    "result = detector.test_demographic_parity(\n",
    "    group_a_scores=engineering_scores,\n",
    "    group_b_scores=marketing_scores,\n",
    "    group_a_name=\"Engineering Dept\",\n",
    "    group_b_name=\"Marketing Dept\"\n",
    ")\n",
    "\n",
    "print(\"Test Case 2: Department Quality Comparison\")\n",
    "print(f\"  Engineering avg: {result['group_a']['avg_score']}\")\n",
    "print(f\"  Marketing avg: {result['group_b']['avg_score']}\")\n",
    "print(f\"  Relative disparity: {result['disparity']['relative'] * 100:.1f}%\")\n",
    "print(f\"  Bias detected: {result['bias_detected']}\")\n",
    "print(f\"  Severity: {result['severity']}\")\n",
    "\n",
    "# Expected: bias_detected = True (disparity >10%, likely medium severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Bias Testing Summary\n",
    "summary = detector.get_summary()\n",
    "\n",
    "print(\"Bias Testing Summary\")\n",
    "print(f\"  Total tests: {summary['total_tests']}\")\n",
    "print(f\"  Bias detected: {summary['bias_detected']} tests\")\n",
    "print(f\"  Bias rate: {summary['bias_rate'] * 100:.1f}%\")\n",
    "print(f\"\\nSeverity breakdown:\")\n",
    "for severity, count in summary['severities'].items():\n",
    "    print(f\"    {severity}: {count}\")\n",
    "\n",
    "# Add results to model card\n",
    "card.set_ethical_considerations(\n",
    "    fairness_testing=summary,\n",
    "    bias_mitigation=[\n",
    "        \"Regular demographic testing across regions and departments\",\n",
    "        \"Balanced document collection from all business units\",\n",
    "        \"Hybrid search to reduce semantic bias\"\n",
    "    ],\n",
    "    privacy_measures=[\n",
    "        \"PII detection and redaction\",\n",
    "        \"Access controls by user role\",\n",
    "        \"Audit logging for compliance\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Bias testing results added to model card\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVED_SECTION:2** (Bias Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Human-in-the-Loop Workflows\n",
    "\n",
    "### When to Require Human Review\n",
    "\n",
    "**High-Risk Query Indicators (Keywords):**\n",
    "- Legal: \"lawsuit\", \"legal advice\", \"compliance violation\"\n",
    "- HR: \"termination\", \"fire\", \"hire\", \"promotion\", \"discrimination\"\n",
    "- Financial: \"investment\", \"financial advice\", \"credit\"\n",
    "- Medical: \"diagnosis\", \"treatment\", \"medical advice\"\n",
    "\n",
    "**Workflow:**\n",
    "1. Classify query risk (HIGH or LOW)\n",
    "2. If HIGH-RISK: Route to review queue, block auto-response\n",
    "3. Human reviewer approves or rejects within SLA (e.g., 30 minutes)\n",
    "4. Audit trail logs classification, reviewer decision, timestamp\n",
    "\n",
    "**Critical:** Technical enforcement prevents bypass - code blocks auto-response for HIGH-risk queries even under pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Initialize Human-in-the-Loop Workflow\n",
    "workflow = HumanInTheLoopWorkflow()\n",
    "\n",
    "print(\"✓ HumanInTheLoopWorkflow initialized\")\n",
    "print(f\"  High-risk keywords: {len(workflow.high_risk_keywords)}\")\n",
    "print(f\"  Examples: {workflow.high_risk_keywords[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Low-Risk Query Example\n",
    "query_1 = \"What is our vacation policy for new employees?\"\n",
    "\n",
    "result = workflow.process_query(\n",
    "    query=query_1,\n",
    "    user_context={\"department\": \"HR\", \"user\": \"employee123\"}\n",
    ")\n",
    "\n",
    "print(f\"Query: {query_1}\")\n",
    "print(f\"  Status: {result['status']}\")\n",
    "print(f\"  Risk level: {result.get('classification', {}).get('risk_level', 'N/A')}\")\n",
    "print(f\"  Requires review: {result.get('classification', {}).get('requires_review', False)}\")\n",
    "\n",
    "# Expected: status = 'approved', can proceed without review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: High-Risk Query Example (Legal)\n",
    "query_2 = \"What are the legal implications of terminating an employee for poor performance?\"\n",
    "\n",
    "result = workflow.process_query(\n",
    "    query=query_2,\n",
    "    user_context={\"department\": \"HR\", \"user\": \"manager456\"}\n",
    ")\n",
    "\n",
    "print(f\"Query: {query_2}\")\n",
    "print(f\"  Status: {result['status']}\")\n",
    "print(f\"  Queue ID: {result.get('queue_id', 'N/A')}\")\n",
    "print(f\"  Queue position: {result.get('queue_position', 'N/A')}\")\n",
    "print(f\"  Estimated wait: {result.get('estimated_wait', 'N/A')}\")\n",
    "\n",
    "# Expected: status = 'queued_for_review', blocked until human approves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: High-Risk Query Example (Financial)\n",
    "query_3 = \"Should we invest company funds in cryptocurrency?\"\n",
    "\n",
    "result = workflow.process_query(query=query_3)\n",
    "\n",
    "print(f\"Query: {query_3}\")\n",
    "print(f\"  Status: {result['status']}\")\n",
    "print(f\"  Queue ID: {result.get('queue_id', 'N/A')}\")\n",
    "\n",
    "# Expected: status = 'queued_for_review' (financial advice keyword detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Review Queue Status\n",
    "queue_status = workflow.get_queue_status()\n",
    "\n",
    "print(\"Human Review Queue Status\")\n",
    "print(f\"  Total queued: {queue_status['total_queued']}\")\n",
    "print(f\"  Pending review: {queue_status['pending_review']}\")\n",
    "print(f\"  Approved: {queue_status['approved']}\")\n",
    "print(f\"  Rejected: {queue_status['rejected']}\")\n",
    "print(f\"  Audit log size: {queue_status['audit_log_size']}\")\n",
    "\n",
    "# Expected: 2 queries in queue (legal and financial), audit log has 3 entries (including low-risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVED_SECTION:3** (Human-in-the-Loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Governance Committee Review\n",
    "\n",
    "### Committee Structure\n",
    "\n",
    "**5-Member Committee (Cross-Functional):**\n",
    "1. **Security:** Assesses cybersecurity risks, access controls\n",
    "2. **Legal:** Evaluates regulatory compliance, liability\n",
    "3. **Privacy:** Reviews data protection, PII handling\n",
    "4. **Product:** Considers user impact, feature value\n",
    "5. **Engineering:** Evaluates technical feasibility, performance\n",
    "\n",
    "**Approval Threshold:** 75% (4 of 5 votes required)\n",
    "\n",
    "**Review Cadence:** Quarterly for routine updates, ad-hoc for major changes\n",
    "\n",
    "**Changes Requiring Review:**\n",
    "- Model upgrades (GPT-3.5 → GPT-4)\n",
    "- New data sources\n",
    "- Algorithm changes (semantic → hybrid search)\n",
    "- Deployment to new user groups\n",
    "- Response to critical incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Initialize Governance Reviewer\n",
    "reviewer = GovernanceReviewer(\n",
    "    committee_members=[\"Security\", \"Legal\", \"Privacy\", \"Product\", \"Engineering\"],\n",
    "    review_cadence=\"Quarterly\",\n",
    "    approval_threshold=0.75  # 75% = 4 of 5 votes\n",
    ")\n",
    "\n",
    "print(\"✓ GovernanceReviewer initialized\")\n",
    "print(f\"  Committee size: {len(reviewer.committee_members)}\")\n",
    "print(f\"  Members: {', '.join(reviewer.committee_members)}\")\n",
    "print(f\"  Approval threshold: {reviewer.approval_threshold * 100}%\")\n",
    "print(f\"  Votes needed: {int(len(reviewer.committee_members) * reviewer.approval_threshold)} of {len(reviewer.committee_members)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Submit Change for Review\n",
    "review_result = reviewer.submit_for_review(\n",
    "    change_type=\"model_update\",\n",
    "    description=\"Upgrade from GPT-3.5 to GPT-4 for improved accuracy\",\n",
    "    impact_assessment=\"Expected 15% improvement in answer quality, no change to latency, +$500/month cost\",\n",
    "    submitted_by=\"AI Engineering Team\"\n",
    ")\n",
    "\n",
    "print(\"Change Submitted for Review\")\n",
    "print(f\"  Review ID: {review_result['review_id']}\")\n",
    "print(f\"  Status: {review_result['status']}\")\n",
    "print(f\"  Committee size: {review_result['committee_size']}\")\n",
    "print(f\"  Approval threshold: {review_result['approval_threshold'] * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Committee Voting\n",
    "# Simulate committee members voting\n",
    "\n",
    "review_id = review_result['review_id']\n",
    "\n",
    "# Security approves\n",
    "vote_1 = reviewer.cast_vote(\n",
    "    review_id=review_id,\n",
    "    committee_member=\"Security\",\n",
    "    vote=\"approve\",\n",
    "    comments=\"Security assessment passed, no new vulnerabilities introduced\"\n",
    ")\n",
    "print(f\"Security: {vote_1['status']} - {vote_1['votes_cast']}/{vote_1['votes_needed']} votes\")\n",
    "\n",
    "# Legal approves\n",
    "vote_2 = reviewer.cast_vote(\n",
    "    review_id=review_id,\n",
    "    committee_member=\"Legal\",\n",
    "    vote=\"approve\",\n",
    "    comments=\"No regulatory concerns, maintains compliance\"\n",
    ")\n",
    "print(f\"Legal: {vote_2['status']} - {vote_2['votes_cast']}/{vote_2['votes_needed']} votes\")\n",
    "\n",
    "# Privacy approves\n",
    "vote_3 = reviewer.cast_vote(\n",
    "    review_id=review_id,\n",
    "    committee_member=\"Privacy\",\n",
    "    vote=\"approve\",\n",
    "    comments=\"No change to data handling, PII controls remain in place\"\n",
    ")\n",
    "print(f\"Privacy: {vote_3['status']} - {vote_3['votes_cast']}/{vote_3['votes_needed']} votes\")\n",
    "\n",
    "# Product rejects (concerned about cost)\n",
    "vote_4 = reviewer.cast_vote(\n",
    "    review_id=review_id,\n",
    "    committee_member=\"Product\",\n",
    "    vote=\"reject\",\n",
    "    comments=\"Cost increase not justified for 15% quality gain, suggest A/B test first\"\n",
    ")\n",
    "print(f\"Product: {vote_4['status']} - {vote_4['votes_cast']}/{vote_4['votes_needed']} votes\")\n",
    "\n",
    "# Engineering approves (final vote)\n",
    "vote_5 = reviewer.cast_vote(\n",
    "    review_id=review_id,\n",
    "    committee_member=\"Engineering\",\n",
    "    vote=\"approve\",\n",
    "    comments=\"Technical implementation straightforward, quality improvement measurable\"\n",
    ")\n",
    "print(f\"Engineering: {vote_5['status']} - {vote_5['votes_cast']}/{vote_5['votes_needed']} votes\")\n",
    "\n",
    "print(f\"\\nFinal Decision: {vote_5['current_decision']}\")\n",
    "print(\"(4 of 5 votes approve = 80% > 75% threshold → APPROVED)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVED_SECTION:4** (Governance Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Incident Tracking and Escalation\n",
    "\n",
    "### Severity Levels and SLAs\n",
    "\n",
    "**LOW:** Minor issue, track for patterns\n",
    "- Examples: Query timeout, slow response\n",
    "- Action: Log and review at next quarterly meeting\n",
    "- Escalation: None\n",
    "\n",
    "**MEDIUM:** Needs committee review\n",
    "- Examples: Hallucination, incorrect policy information\n",
    "- Action: Immediate correction, review at next meeting\n",
    "- Escalation: Committee review within 1 week\n",
    "\n",
    "**HIGH:** Immediate committee attention\n",
    "- Examples: 20% bias disparity detected, repeated failures\n",
    "- Action: Pause deployment to affected groups\n",
    "- Escalation: Committee notification within 24 hours\n",
    "\n",
    "**CRITICAL:** System shutdown, executive escalation\n",
    "- Examples: Privacy breach, PII exposure, regulatory violation\n",
    "- Action: Immediate shutdown, notify affected users\n",
    "- Escalation: Executive team + Board within 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Report Low Severity Incident\n",
    "incident_1 = reviewer.report_incident(\n",
    "    incident_type=\"query_timeout\",\n",
    "    description=\"System timed out on complex multi-part query with 5 sub-questions\",\n",
    "    severity=\"low\",\n",
    "    reported_by=\"Operations Team\"\n",
    ")\n",
    "\n",
    "print(\"Incident 1: LOW Severity\")\n",
    "print(f\"  Incident ID: {incident_1['incident_id']}\")\n",
    "print(f\"  Status: {incident_1['status']}\")\n",
    "print(f\"  Escalated: {incident_1['escalated']}\")\n",
    "print(f\"  Next steps: {incident_1['next_steps']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: Report High Severity Incident\n",
    "incident_2 = reviewer.report_incident(\n",
    "    incident_type=\"bias_detected\",\n",
    "    description=\"20% quality disparity detected between North America and Asia-Pacific regions in quarterly testing\",\n",
    "    severity=\"high\",\n",
    "    reported_by=\"Data Science Team\"\n",
    ")\n",
    "\n",
    "print(\"Incident 2: HIGH Severity\")\n",
    "print(f\"  Incident ID: {incident_2['incident_id']}\")\n",
    "print(f\"  Status: {incident_2['status']}\")\n",
    "print(f\"  Escalated: {incident_2['escalated']}\")\n",
    "print(f\"  Next steps: {incident_2['next_steps']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Report Critical Severity Incident\n",
    "incident_3 = reviewer.report_incident(\n",
    "    incident_type=\"privacy_breach\",\n",
    "    description=\"System exposed PII from one user to another user's query results (leaked salary info)\",\n",
    "    severity=\"critical\",\n",
    "    reported_by=\"Security Team\"\n",
    ")\n",
    "\n",
    "print(\"Incident 3: CRITICAL Severity\")\n",
    "print(f\"  Incident ID: {incident_3['incident_id']}\")\n",
    "print(f\"  Status: {incident_3['status']}\")\n",
    "print(f\"  Escalated: {incident_3['escalated']}\")\n",
    "print(f\"  Next steps: {incident_3['next_steps']}\")\n",
    "print(\"\\n⚠️ CRITICAL incidents trigger immediate executive escalation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVED_SECTION:5** (Incident Tracking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Governance Health Metrics\n",
    "\n",
    "### Key Performance Indicators\n",
    "\n",
    "**Review Metrics:**\n",
    "- Approval rate (target: >60%)\n",
    "- Average time to decision (target: <2 weeks)\n",
    "- Committee participation (target: 100% voting)\n",
    "\n",
    "**Incident Metrics:**\n",
    "- Total incidents per quarter\n",
    "- Critical incidents (target: 0)\n",
    "- Average time to resolution\n",
    "\n",
    "**Bias Metrics:**\n",
    "- Tests conducted per release (minimum 1)\n",
    "- Bias detection rate (monitored, no fixed target)\n",
    "- Remediation completion rate (target: 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: Governance Summary\n",
    "summary = reviewer.get_governance_summary()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GOVERNANCE HEALTH SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nCommittee Configuration:\")\n",
    "print(f\"  Members: {', '.join(summary['committee']['members'])}\")\n",
    "print(f\"  Size: {summary['committee']['size']}\")\n",
    "print(f\"  Review cadence: {summary['committee']['review_cadence']}\")\n",
    "print(f\"  Approval threshold: {summary['committee']['approval_threshold'] * 100}%\")\n",
    "\n",
    "print(\"\\nReview Activity:\")\n",
    "print(f\"  Total reviews: {summary['reviews']['total']}\")\n",
    "print(f\"  Approved: {summary['reviews']['approved']}\")\n",
    "print(f\"  Rejected: {summary['reviews']['rejected']}\")\n",
    "print(f\"  Pending: {summary['reviews']['pending']}\")\n",
    "print(f\"  Approval rate: {summary['reviews']['approval_rate'] * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nIncident Tracking:\")\n",
    "print(f\"  Total incidents: {summary['incidents']['total']}\")\n",
    "print(f\"  Open: {summary['incidents']['open']}\")\n",
    "print(f\"  Critical: {summary['incidents']['critical']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVED_SECTION:6** (Governance Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10: Complete Governance Workflow Integration\n",
    "\n",
    "### End-to-End Example: Deploying a New RAG System\n",
    "\n",
    "**Step 1:** Create model card documenting all 10 sections\n",
    "**Step 2:** Run bias testing across demographics (regions, departments, languages)\n",
    "**Step 3:** Configure human-in-the-loop for high-stakes queries\n",
    "**Step 4:** Submit for governance committee review\n",
    "**Step 5:** Committee votes (75% approval required)\n",
    "**Step 6:** Deploy with monitoring and quarterly reviews\n",
    "\n",
    "This workflow ensures compliance with NIST AI RMF, EU AI Act, and corporate governance policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: Complete Workflow Demonstration\n",
    "print(\"COMPLETE AI GOVERNANCE WORKFLOW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nStep 1: Model Card Created ✓\")\n",
    "print(f\"  System: {card.model_name} v{card.model_version}\")\n",
    "print(f\"  Sections: 10/10 complete\")\n",
    "print(f\"  Exports: JSON, Markdown\")\n",
    "\n",
    "print(\"\\nStep 2: Bias Testing Conducted ✓\")\n",
    "bias_summary = detector.get_summary()\n",
    "print(f\"  Tests run: {bias_summary['total_tests']}\")\n",
    "print(f\"  Bias detected: {bias_summary['bias_detected']} tests\")\n",
    "print(f\"  Action: Results added to model card ethical considerations\")\n",
    "\n",
    "print(\"\\nStep 3: Human-in-the-Loop Configured ✓\")\n",
    "hitl_status = workflow.get_queue_status()\n",
    "print(f\"  High-risk keywords: {len(workflow.high_risk_keywords)}\")\n",
    "print(f\"  Queries routed to review: {hitl_status['total_queued']}\")\n",
    "print(f\"  Audit log entries: {hitl_status['audit_log_size']}\")\n",
    "\n",
    "print(\"\\nStep 4: Governance Review Submitted ✓\")\n",
    "gov_summary = reviewer.get_governance_summary()\n",
    "print(f\"  Reviews submitted: {gov_summary['reviews']['total']}\")\n",
    "print(f\"  Approval rate: {gov_summary['reviews']['approval_rate'] * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nStep 5: Incident Tracking Active ✓\")\n",
    "print(f\"  Incidents reported: {gov_summary['incidents']['total']}\")\n",
    "print(f\"  Critical incidents: {gov_summary['incidents']['critical']}\")\n",
    "print(f\"  Open incidents: {gov_summary['incidents']['open']}\")\n",
    "\n",
    "print(\"\\nStep 6: Regulatory Compliance ✓\")\n",
    "print(\"  NIST AI RMF: Govern, Map, Measure, Manage functions implemented\")\n",
    "print(\"  EU AI Act: High-risk system documentation complete\")\n",
    "print(\"  GDPR/DPDPA: Transparency and accountability mechanisms in place\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GOVERNANCE WORKFLOW COMPLETE\")\n",
    "print(\"System ready for deployment with full governance oversight\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVED_SECTION:7** (Complete Workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 11: Cost-Benefit Analysis for GCCs\n",
    "\n",
    "### Investment Justification\n",
    "\n",
    "**Small GCC (500 employees, 10 tenants):**\n",
    "- Annual Cost: ₹9.2L ($11K USD)\n",
    "- ROI: Avoiding single DPDPA fine (₹250Cr max) = 2700× return\n",
    "\n",
    "**Medium GCC (2000 employees, 30 tenants):**\n",
    "- Annual Cost: ₹70L ($84K USD)\n",
    "- ROI: Avoiding GDPR fine (€20M = ₹180Cr) = 257× return\n",
    "\n",
    "**Large GCC (5000 employees, 50+ tenants):**\n",
    "- Annual Cost: ₹2.5Cr ($300K USD)\n",
    "- ROI: Avoiding EU AI Act fine (€30M = ₹270Cr) = 108× return\n",
    "\n",
    "**Key Insight:** Preventing a single major regulatory fine provides 10-100× return on governance investment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 12: Common Governance Failures to Avoid\n",
    "\n",
    "### 1. Governance as Theater\n",
    "**Problem:** Model cards created but ignored, committees rubber-stamp decisions\n",
    "**Fix:** Give committee veto power, include executives, tie updates to deployment\n",
    "\n",
    "### 2. Stale Documentation\n",
    "**Problem:** Model cards become outdated as system evolves\n",
    "**Fix:** Automate updates in deployment pipeline, enforce version matching\n",
    "\n",
    "### 3. Bias Testing Without Remediation\n",
    "**Problem:** Bias detected but no owner or timeline to fix\n",
    "**Fix:** Assign owners, set deadlines, critical bias blocks deployment\n",
    "\n",
    "### 4. Human-in-the-Loop Bypassed\n",
    "**Problem:** Review requirements abandoned when queues back up\n",
    "**Fix:** Technical enforcement (code blocks auto-response), plan capacity\n",
    "\n",
    "### 5. Committee Without Authority\n",
    "**Problem:** Advisory-only committee cannot block risky deployments\n",
    "**Fix:** Include executives with veto power, document escalation paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **\"Out-of-scope uses protect from liability\"** - Document prohibited uses explicitly in model cards\n",
    "\n",
    "2. **Governance requires decision authority** - Advisory committees fail; ensure veto power\n",
    "\n",
    "3. **Technical enforcement prevents bypass** - Code blocks high-risk auto-responses\n",
    "\n",
    "4. **Bias testing must lead to remediation** - Detection without action is theater\n",
    "\n",
    "5. **ROI justification is compelling** - Single regulatory fine avoidance = 10-100× return\n",
    "\n",
    "6. **Three pillars are essential** - Fairness, Transparency, Accountability working together\n",
    "\n",
    "7. **Documentation enables compliance** - Model cards satisfy NIST, EU AI Act, GDPR requirements\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **L3 M4.2:** Security & Privacy Controls - PII detection, encryption, access controls\n",
    "- **Practice:** Create model card for your own RAG system\n",
    "- **Explore:** Run bias tests on production query logs\n",
    "- **Implement:** Configure human-in-the-loop for high-stakes queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVED_SECTION:8** (Final Summary)\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook Complete!** All sections saved incrementally.\n",
    "\n",
    "This notebook demonstrated:\n",
    "- ✓ Model card generation (10 sections)\n",
    "- ✓ Bias detection with statistical testing\n",
    "- ✓ Human-in-the-loop query routing\n",
    "- ✓ Governance committee voting\n",
    "- ✓ Incident tracking and escalation\n",
    "- ✓ Complete workflow integration\n",
    "- ✓ Cost-benefit analysis\n",
    "- ✓ Common failure modes and fixes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
