{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L3 M3.2: Automated Compliance Testing\n",
    "\n",
    "## Learning Arc\n",
    "\n",
    "**Duration:** 40-45 minutes\n",
    "\n",
    "### Concepts Covered:\n",
    "\n",
    "1. **Policy-as-Code Fundamentals** - Transform compliance from documentation to executable policies\n",
    "2. **Open Policy Agent (OPA) & Rego** - Industry-standard policy engine and declarative policy language\n",
    "3. **PII Detection Patterns** - Regex-based and ML-enhanced detection for GDPR/DPDPA compliance\n",
    "4. **Test Pyramid Implementation** - 70% unit, 20% integration, 10% E2E testing strategy\n",
    "5. **CI/CD Integration** - Automated compliance gates preventing violations before production\n",
    "6. **Audit Evidence Generation** - Automated test results for SOC 2, ISO 27001 audits\n",
    "\n",
    "### Learning Outcomes:\n",
    "\n",
    "By completing this notebook, you will:\n",
    "\n",
    "1. Implement policy-as-code with OPA/Rego\n",
    "2. Build automated compliance test suites\n",
    "3. Integrate testing into CI/CD with deployment gates\n",
    "4. Create regression tests for control persistence\n",
    "5. Generate automated audit evidence\n",
    "6. Write and test Rego policies for RAG systems\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- Generic CCC L1: RAG MVP fundamentals (M1-M4)\n",
    "- GCC Compliance M1: Regulatory Foundations\n",
    "- GCC Compliance M2: Core Controls\n",
    "- GCC Compliance M3.1: Monitoring Dashboards\n",
    "\n",
    "---\n",
    "\n",
    "**Key Question:** How do you prevent compliance violations *before* production, not after the 2 AM incident?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: OFFLINE Mode Guard\n",
    "\n",
    "This notebook works in both ONLINE (with OPA/Presidio) and OFFLINE (regex-only) modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from config import check_service_availability, get_config\n",
    "\n",
    "# Check service availability\n",
    "availability = check_service_availability()\n",
    "config = get_config()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"L3 M3.2: Automated Compliance Testing\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nService Status:\")\n",
    "print(f\"  OPA Available: {availability['opa']}\")\n",
    "print(f\"  Presidio Available: {availability['presidio']}\")\n",
    "print(f\"\\nMode: {'FULL' if all(availability.values()) else 'REGEX-ONLY (OFFLINE)'}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "if not availability['opa']:\n",
    "    print(\"⚠️ Running in OFFLINE mode (regex-based PII detection only)\")\n",
    "    print(\"\\nTo enable full functionality:\")\n",
    "    print(\"  1. Install OPA: https://www.openpolicyagent.org/docs/latest/\")\n",
    "    print(\"  2. Set OPA_ENABLED=true in .env\")\n",
    "    print(\"  3. Optional: pip install presidio-analyzer presidio-anonymizer\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: The Compliance Nightmare Scenario\n",
    "\n",
    "### The Problem\n",
    "\n",
    "**2 AM on a Monday:** Your PII detection dashboard alerts fire. Customer Social Security Numbers have been embedded in your vector database for the past 3 weeks. GDPR violation. DPDPA violation. Audit failure imminent.\n",
    "\n",
    "**Root Cause:** No automated validation before embedding - relied on manual reviews.\n",
    "\n",
    "**The Question:** How could this have been prevented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional approach (NO validation)\n",
    "from src.l3_m3_monitoring_reporting import contains_pii\n",
    "\n",
    "# Dangerous text with PII\n",
    "dangerous_text = \"Customer profile: Jane Doe, SSN 123-45-6789, Account #12345\"\n",
    "\n",
    "print(\"Traditional Approach (Manual Review):\")\n",
    "print(f\"Text: {dangerous_text[:50]}...\")\n",
    "print(\"\\n❌ Embedded without validation - PII LEAKED!\")\n",
    "print(\"\\nResult: GDPR Article 17 violation, audit failure\\n\")\n",
    "\n",
    "# Automated approach\n",
    "print(\"=\"*60)\n",
    "print(\"Automated Compliance Approach:\")\n",
    "has_pii = contains_pii(dangerous_text)\n",
    "print(f\"PII Detected: {has_pii}\")\n",
    "\n",
    "if has_pii:\n",
    "    print(\"\\n✓ BLOCKED before embedding\")\n",
    "    print(\"Violation prevented in CI/CD pipeline\")\n",
    "else:\n",
    "    print(\"Safe to embed\")\n",
    "\n",
    "# Expected: PII detected, operation blocked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Policy-as-Code Fundamentals\n",
    "\n",
    "### Documentation-Based vs. Code-Based Compliance\n",
    "\n",
    "**Traditional (Documentation-Based):**\n",
    "- Manual checklist: \"Scan for PII before embedding\"\n",
    "- Review process: Human reads docs, checks code\n",
    "- Failure mode: Human error, inconsistent application\n",
    "\n",
    "**Policy-as-Code (Executable):**\n",
    "- Executable policy: `deny { contains_pii(input.text) }`\n",
    "- Automated execution: CI/CD runs tests on every commit\n",
    "- Failure mode: Only false negatives (~5%), not human error\n",
    "\n",
    "### OPA Architecture\n",
    "\n",
    "```\n",
    "┌──────────────┐\n",
    "│   Input      │  ← Operation + Data (e.g., \"embed\" + text)\n",
    "└──────┬───────┘\n",
    "       │\n",
    "       v\n",
    "┌──────────────┐\n",
    "│ Policy Engine│  ← OPA evaluates Rego policies\n",
    "│    (OPA)     │\n",
    "└──────┬───────┘\n",
    "       │\n",
    "       v\n",
    "┌──────────────┐\n",
    "│  Decision    │  ← Allow/Deny + Violations\n",
    "└──────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.l3_m3_monitoring_reporting import evaluate_policy\n",
    "\n",
    "# Example policy evaluation\n",
    "input_data = {\n",
    "    'operation': 'embed',\n",
    "    'text': 'Financial compliance policy document',\n",
    "    'pii_redacted': False\n",
    "}\n",
    "\n",
    "decision = evaluate_policy(input_data, policy='pii')\n",
    "\n",
    "print(\"Policy Evaluation Result:\")\n",
    "print(f\"  Input: {input_data['text']}\")\n",
    "print(f\"  Policy: {decision['policy']}\")\n",
    "print(f\"  Decision: {'ALLOW' if decision['allow'] else 'DENY'}\")\n",
    "print(f\"  PII Detected: {decision.get('pii_detected', 'N/A')}\")\n",
    "print(f\"  Violations: {decision['violations']}\")\n",
    "\n",
    "# Expected: Allow (no PII in clean text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: PII Detection Implementation\n",
    "\n",
    "### Supported PII Types\n",
    "\n",
    "1. **SSN** - Social Security Numbers (xxx-xx-xxxx)\n",
    "2. **Email** - Email addresses\n",
    "3. **Credit Card** - Card numbers (16 digits)\n",
    "4. **Phone** - US phone numbers\n",
    "\n",
    "### Detection Methods\n",
    "\n",
    "- **Regex-based (Default):** Fast, transparent, zero dependencies\n",
    "- **Presidio-enhanced (Optional):** ML-based, 15+ entity types, edge case handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.l3_m3_monitoring_reporting import PIIDetector, PIIType\n",
    "\n",
    "detector = PIIDetector()\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    (\"SSN: 123-45-6789\", \"SSN\"),\n",
    "    (\"Email: john.doe@example.com\", \"Email\"),\n",
    "    (\"Card: 4532-1234-5678-9010\", \"Credit Card\"),\n",
    "    (\"Phone: (555) 123-4567\", \"Phone\"),\n",
    "    (\"Clean document about compliance\", \"No PII\")\n",
    "]\n",
    "\n",
    "print(\"PII Detection Test Results:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for text, expected in test_cases:\n",
    "    result = detector.detect(text)\n",
    "    status = \"✓\" if result.has_pii else \"○\"\n",
    "    pii_types = \", \".join([t.value for t in result.pii_types]) if result.pii_types else \"none\"\n",
    "    \n",
    "    print(f\"{status} {expected:12} | Text: {text[:40]:40} | Detected: {pii_types}\")\n",
    "\n",
    "# Expected: First 4 detect PII, last one clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Redaction Quality Validation\n",
    "\n",
    "### Policy Requirement\n",
    "\n",
    "If PII is detected, it must be **properly redacted** using `[REDACTED]` markers.\n",
    "\n",
    "**Valid Redaction:**\n",
    "```\n",
    "Customer SSN: [REDACTED]\n",
    "Email: [REDACTED]\n",
    "```\n",
    "\n",
    "**Invalid (Partial) Redaction:**\n",
    "```\n",
    "Customer SSN: [REDACTED], Email: real@example.com  ← Still has email!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.l3_m3_monitoring_reporting import redaction_quality_sufficient\n",
    "\n",
    "# Test redaction quality\n",
    "redaction_cases = [\n",
    "    (\"SSN: [REDACTED], Email: [REDACTED]\", \"Full redaction\"),\n",
    "    (\"SSN: [REDACTED], Email: real@example.com\", \"Partial redaction\"),\n",
    "    (\"SSN: 123-45-6789\", \"No redaction\"),\n",
    "    (\"Clean text\", \"No PII\")\n",
    "]\n",
    "\n",
    "print(\"Redaction Quality Validation:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for text, description in redaction_cases:\n",
    "    is_sufficient = redaction_quality_sufficient(text)\n",
    "    status = \"✓\" if is_sufficient else \"✗\"\n",
    "    \n",
    "    print(f\"{status} {description:20} | {text[:40]:40} | Sufficient: {is_sufficient}\")\n",
    "\n",
    "# Expected: Only full redaction and clean text pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Complete Compliance Workflow\n",
    "\n",
    "### End-to-End Validation\n",
    "\n",
    "The `check_compliance()` function orchestrates:\n",
    "1. PII detection (regex or Presidio)\n",
    "2. Policy evaluation (OPA logic)\n",
    "3. Redaction quality check\n",
    "4. Violation reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.l3_m3_monitoring_reporting import check_compliance\n",
    "\n",
    "# Workflow examples\n",
    "workflows = [\n",
    "    (\"embed\", \"Financial regulations require proper documentation.\"),\n",
    "    (\"embed\", \"Customer SSN: 123-45-6789\"),\n",
    "    (\"embed\", \"Customer SSN: [REDACTED]\"),\n",
    "    (\"query\", \"What are GDPR Article 17 requirements?\")\n",
    "]\n",
    "\n",
    "print(\"Complete Compliance Workflow:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for operation, text in workflows:\n",
    "    result = check_compliance(operation=operation, text=text)\n",
    "    \n",
    "    status = \"✓ ALLOW\" if result.allowed else \"✗ DENY\"\n",
    "    violations_summary = f\"{len(result.violations)} violation(s)\" if result.violations else \"none\"\n",
    "    \n",
    "    print(f\"\\n{status}\")\n",
    "    print(f\"  Operation: {operation}\")\n",
    "    print(f\"  Text: {text[:50]}\")\n",
    "    print(f\"  Violations: {violations_summary}\")\n",
    "    \n",
    "    if result.violations:\n",
    "        for v in result.violations[:2]:  # Show first 2\n",
    "            print(f\"    - {v[:80]}\")\n",
    "\n",
    "# Expected: Allow clean text and redacted, deny unredacted PII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Test Pyramid Implementation\n",
    "\n",
    "### Test Pyramid Strategy\n",
    "\n",
    "```\n",
    "      /\\        E2E (10%)\n",
    "     /  \\       5-10 tests\n",
    "    /────\\      Full workflow validation\n",
    "   /      \\     \n",
    "  / Integ  \\    Integration (20%)\n",
    " /  (20%)  \\   10-15 tests\n",
    "/────────────\\  Policy + data integration\n",
    "/            \\ \n",
    "/ Unit (70%)  \\ Unit Tests (70%)\n",
    "/──────────────\\ 15-20 tests per category\n",
    "                PII detection, patterns, edge cases\n",
    "```\n",
    "\n",
    "### Target Coverage\n",
    "\n",
    "- **55-77 total tests** per deployment\n",
    "- **95%+ pass rate** for production readiness\n",
    "- **2-5 minute** execution time in CI/CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.l3_m3_monitoring_reporting import run_compliance_tests\n",
    "\n",
    "# Run automated test suite\n",
    "print(\"Executing Compliance Test Suite...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = run_compliance_tests()\n",
    "\n",
    "print(f\"\\nTest Execution Summary:\")\n",
    "print(f\"  Total Tests: {results['total_tests']}\")\n",
    "print(f\"  Passed: {results['passed']} ✓\")\n",
    "print(f\"  Failed: {results['failed']} ✗\")\n",
    "print(f\"  Pass Rate: {results['pass_rate']:.1f}%\")\n",
    "print(f\"\\nCoverage Metrics:\")\n",
    "print(f\"  Total Validations: {results['coverage']['total_tests']}\")\n",
    "print(f\"  Coverage: {results['coverage']['coverage_pct']:.1f}%\")\n",
    "\n",
    "print(f\"\\nSample Test Results (first 5):\")\n",
    "for test in results['results'][:5]:\n",
    "    status = \"✓\" if test['passed'] else \"✗\"\n",
    "    print(f\"  {status} {test['name']}\")\n",
    "\n",
    "# Expected: 95%+ pass rate with 10 tests shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Writing Rego Policies\n",
    "\n",
    "### Sample Rego Policy (Conceptual)\n",
    "\n",
    "```rego\n",
    "package ragcompliance.pii\n",
    "\n",
    "# Default deny principle\n",
    "default allow_embedding = false\n",
    "\n",
    "# Helper: Check if text contains PII\n",
    "contains_pii(text) {\n",
    "    regex.match(`\\\\b\\\\d{3}-\\\\d{2}-\\\\d{4}\\\\b`, text)  # SSN\n",
    "}\n",
    "\n",
    "contains_pii(text) {\n",
    "    regex.match(`[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Z|a-z]{2,}`, text)  # Email\n",
    "}\n",
    "\n",
    "# Helper: Check redaction quality\n",
    "redaction_quality_sufficient(text) {\n",
    "    contains(text, \"[REDACTED]\")\n",
    "    not contains_pii(text)  # No unredacted PII remains\n",
    "}\n",
    "\n",
    "# Allow rule: No PII detected\n",
    "allow_embedding {\n",
    "    not contains_pii(input.text)\n",
    "}\n",
    "\n",
    "# Allow rule: PII properly redacted\n",
    "allow_embedding {\n",
    "    contains_pii(input.text)\n",
    "    redaction_quality_sufficient(input.text)\n",
    "}\n",
    "\n",
    "# Violation: Unredacted PII\n",
    "violation[msg] {\n",
    "    contains_pii(input.text)\n",
    "    not redaction_quality_sufficient(input.text)\n",
    "    msg := sprintf(\"PII detected without redaction: GDPR Article 17 violation\", [])\n",
    "}\n",
    "```\n",
    "\n",
    "### Policy Components\n",
    "\n",
    "1. **Package Declaration** - Namespace (e.g., `ragcompliance.pii`)\n",
    "2. **Default Rules** - Security principle (default deny)\n",
    "3. **Helper Functions** - Reusable logic (PII detection, redaction check)\n",
    "4. **Allow Rules** - Explicit conditions permitting operations\n",
    "5. **Violation Messages** - Formatted error output for audits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.l3_m3_monitoring_reporting import OPAPolicyEngine\n",
    "\n",
    "# Simulate OPA policy evaluation\n",
    "engine = OPAPolicyEngine()\n",
    "\n",
    "# Test policy logic\n",
    "policy_tests = [\n",
    "    {\n",
    "        'operation': 'embed',\n",
    "        'text': 'Clean document',\n",
    "        'pii_redacted': False,\n",
    "        'expected': 'allow'\n",
    "    },\n",
    "    {\n",
    "        'operation': 'embed',\n",
    "        'text': 'SSN: 123-45-6789',\n",
    "        'pii_redacted': False,\n",
    "        'expected': 'deny'\n",
    "    },\n",
    "    {\n",
    "        'operation': 'embed',\n",
    "        'text': 'SSN: [REDACTED]',\n",
    "        'pii_redacted': True,\n",
    "        'expected': 'allow'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Rego Policy Logic Validation:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for test in policy_tests:\n",
    "    decision = engine.evaluate_pii_policy(test)\n",
    "    actual = 'allow' if decision['allow'] else 'deny'\n",
    "    match = \"✓\" if actual == test['expected'] else \"✗\"\n",
    "    \n",
    "    print(f\"{match} Expected: {test['expected']:5} | Actual: {actual:5} | Text: {test['text'][:30]}\")\n",
    "\n",
    "# Expected: All tests match expected behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: CI/CD Integration Pattern\n",
    "\n",
    "### GitHub Actions Workflow\n",
    "\n",
    "```yaml\n",
    "name: Compliance Gate\n",
    "\n",
    "on: [push, pull_request]\n",
    "\n",
    "jobs:\n",
    "  compliance-tests:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - name: Checkout code\n",
    "        uses: actions/checkout@v3\n",
    "\n",
    "      - name: Install OPA\n",
    "        run: |\n",
    "          curl -L -o opa https://openpolicyagent.org/downloads/latest/opa_linux_amd64\n",
    "          chmod +x opa && sudo mv opa /usr/local/bin/\n",
    "\n",
    "      - name: Setup Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: '3.10'\n",
    "\n",
    "      - name: Install dependencies\n",
    "        run: pip install -r requirements.txt\n",
    "\n",
    "      - name: Run compliance tests\n",
    "        run: pytest tests/ --cov-fail-under=95\n",
    "\n",
    "      - name: Block on violations\n",
    "        if: failure()\n",
    "        run: |\n",
    "          echo \"❌ Compliance tests failed - deployment blocked\"\n",
    "          exit 1\n",
    "```\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "1. **Prevention** - Violations caught before merge\n",
    "2. **Speed** - 2-5 minute execution time\n",
    "3. **Evidence** - Test results for audit trail\n",
    "4. **Regression** - Every commit validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate CI/CD gate\n",
    "from src.l3_m3_monitoring_reporting import ComplianceValidator\n",
    "\n",
    "validator = ComplianceValidator()\n",
    "\n",
    "# Simulated commit changes\n",
    "commit_changes = [\n",
    "    (\"New feature: compliance dashboard\", \"embed\"),\n",
    "    (\"User data: SSN 123-45-6789\", \"store\"),  # This should fail\n",
    "    (\"Updated policy documentation\", \"embed\")\n",
    "]\n",
    "\n",
    "print(\"CI/CD Compliance Gate Simulation:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_passed = True\n",
    "\n",
    "for text, operation in commit_changes:\n",
    "    result = validator.validate(operation, text)\n",
    "    \n",
    "    if result.allowed:\n",
    "        print(f\"✓ PASS | {text[:40]}\")\n",
    "    else:\n",
    "        print(f\"✗ FAIL | {text[:40]}\")\n",
    "        print(f\"  Violations: {result.violations[0][:60]}...\")\n",
    "        all_passed = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_passed:\n",
    "    print(\"✓ All checks passed - DEPLOYMENT ALLOWED\")\n",
    "else:\n",
    "    print(\"✗ Compliance gate failed - DEPLOYMENT BLOCKED\")\n",
    "    print(\"Fix violations before merging to main branch\")\n",
    "\n",
    "# Expected: Second commit fails (unredacted SSN), deployment blocked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Metrics & Impact\n",
    "\n",
    "### Key Performance Indicators\n",
    "\n",
    "| Metric | Before Automation | After Automation | Improvement |\n",
    "|--------|------------------|------------------|-------------|\n",
    "| **Audit Prep Time** | 8 hours | 30 minutes | 16x faster |\n",
    "| **Violation Detection** | Post-production | Pre-deployment | 95% prevented |\n",
    "| **Test Execution** | Manual (hours) | Automated (2-5 min) | ~100x faster |\n",
    "| **Coverage** | Variable | 95%+ consistent | Guaranteed |\n",
    "| **Regression Catches** | Rare | 95%+ in CI | Continuous |\n",
    "\n",
    "### Compliance Coverage\n",
    "\n",
    "- **PII Detection:** 99%+ pattern detection accuracy\n",
    "- **Access Control:** 100% unauthorized access blocked (when implemented)\n",
    "- **Audit Logging:** 99.5%+ operation logging\n",
    "- **Overall Regression Prevention:** 95%+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate coverage metrics\n",
    "from src.l3_m3_monitoring_reporting import ComplianceValidator\n",
    "\n",
    "validator = ComplianceValidator()\n",
    "\n",
    "# Simulate month of operations\n",
    "import random\n",
    "\n",
    "operations_sample = [\n",
    "    (\"embed\", \"Clean financial document\"),\n",
    "    (\"query\", \"What are compliance requirements?\"),\n",
    "    (\"embed\", \"Policy framework overview\"),\n",
    "    (\"store\", \"Audit trail record\"),\n",
    "    (\"embed\", \"Regulatory guidelines\")\n",
    "]\n",
    "\n",
    "for _ in range(10):  # Simulate 10 operations\n",
    "    op, text = random.choice(operations_sample)\n",
    "    validator.validate(op, text)\n",
    "\n",
    "coverage = validator.get_test_coverage()\n",
    "\n",
    "print(\"Coverage Metrics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Operations Validated: {coverage['total_tests']}\")\n",
    "print(f\"Passed: {coverage['passed']}\")\n",
    "print(f\"Failed: {coverage['failed']}\")\n",
    "print(f\"Coverage: {coverage['coverage_pct']:.1f}%\")\n",
    "print(\"\\nAll operations validated - 100% coverage achieved\")\n",
    "\n",
    "# Expected: 100% of operations validated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10: Common Failures & Debugging\n",
    "\n",
    "### Top 5 Failure Scenarios\n",
    "\n",
    "1. **False Positives** - Valid data blocked (e.g., dates mistaken for SSN)\n",
    "2. **False Negatives** - PII slips through (international formats, typos)\n",
    "3. **Incomplete Coverage** - Tests pass CI but fail audit\n",
    "4. **Performance Issues** - CI tests exceed 10 minutes\n",
    "5. **Policy Drift** - Policies don't match updated regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug false positive example\n",
    "from src.l3_m3_monitoring_reporting import contains_pii\n",
    "\n",
    "# Edge case: date that looks like SSN pattern\n",
    "edge_cases = [\n",
    "    \"Date format: 123-45-6789\",  # Matches SSN pattern (false positive risk)\n",
    "    \"International phone: +44 20 7123 4567\",  # Non-US format\n",
    "    \"Typo SSN: 123456789\",  # Missing dashes\n",
    "]\n",
    "\n",
    "print(\"Edge Case Detection:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for text in edge_cases:\n",
    "    has_pii = contains_pii(text)\n",
    "    print(f\"{'✓ PII' if has_pii else '○ Clean'} | {text}\")\n",
    "\n",
    "print(\"\\nNote: Regex patterns prioritize precision over recall\")\n",
    "print(\"Edge cases may require pattern tuning or Presidio enhancement\")\n",
    "\n",
    "# Expected: First case may trigger false positive, others may miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 11: Decision Card Review\n",
    "\n",
    "### When to Use Automated Compliance Testing\n",
    "\n",
    "#### ✅ Use When:\n",
    "\n",
    "1. **High-stakes compliance** - Financial services, healthcare, government (SOC 2, ISO 27001, GDPR)\n",
    "2. **Frequent deployments** - CI/CD pipelines with multiple releases per week\n",
    "3. **Audit requirements** - Need automated evidence and control persistence\n",
    "4. **Repeatable testing** - Regression prevention across 55-77 tests\n",
    "5. **Documentation-heavy** - Converting manual checklists to executable policies\n",
    "\n",
    "#### ❌ Don't Use When:\n",
    "\n",
    "1. **Prototype stage** - Pre-PMF, compliance premature\n",
    "2. **Low-risk apps** - Internal tools without PII, no regulations\n",
    "3. **No policy expertise** - Team can't write/maintain Rego\n",
    "4. **One-time audits** - Manual review more efficient\n",
    "5. **Simple rules** - Basic linting suffices\n",
    "\n",
    "#### ⚖️ Trade-offs:\n",
    "\n",
    "- **Learning curve:** 2-4 weeks Rego proficiency\n",
    "- **Setup time:** 1-2 sprints for first suite\n",
    "- **Maintenance:** Policies need updates as regulations change\n",
    "- **Coverage:** 95% catch rate, not 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision framework helper\n",
    "def should_use_automated_testing(context: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate if automated compliance testing is appropriate.\n",
    "    \n",
    "    Args:\n",
    "        context: Dictionary with project characteristics\n",
    "    \n",
    "    Returns:\n",
    "        Recommendation with reasoning\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    reasons = []\n",
    "    \n",
    "    # High-stakes compliance\n",
    "    if context.get('compliance_requirements') in ['SOC2', 'ISO27001', 'GDPR']:\n",
    "        score += 3\n",
    "        reasons.append(\"High-stakes compliance requirements detected\")\n",
    "    \n",
    "    # Deployment frequency\n",
    "    if context.get('deploys_per_week', 0) >= 3:\n",
    "        score += 2\n",
    "        reasons.append(\"Frequent deployments benefit from automation\")\n",
    "    \n",
    "    # Audit needs\n",
    "    if context.get('needs_audit_evidence', False):\n",
    "        score += 2\n",
    "        reasons.append(\"Audit evidence requirement met by automated tests\")\n",
    "    \n",
    "    # Team expertise\n",
    "    if not context.get('has_policy_expertise', False):\n",
    "        score -= 2\n",
    "        reasons.append(\"Team lacks policy expertise - training needed\")\n",
    "    \n",
    "    # Project stage\n",
    "    if context.get('stage') == 'prototype':\n",
    "        score -= 3\n",
    "        reasons.append(\"Prototype stage - premature for automation\")\n",
    "    \n",
    "    recommendation = \"RECOMMEND\" if score >= 3 else \"NOT RECOMMENDED\" if score <= 0 else \"CONSIDER\"\n",
    "    \n",
    "    return {\n",
    "        'recommendation': recommendation,\n",
    "        'score': score,\n",
    "        'reasons': reasons\n",
    "    }\n",
    "\n",
    "# Example contexts\n",
    "contexts = [\n",
    "    {\n",
    "        'name': 'FinTech RAG Production',\n",
    "        'compliance_requirements': 'SOC2',\n",
    "        'deploys_per_week': 5,\n",
    "        'needs_audit_evidence': True,\n",
    "        'has_policy_expertise': True,\n",
    "        'stage': 'production'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Internal Tools Prototype',\n",
    "        'compliance_requirements': None,\n",
    "        'deploys_per_week': 1,\n",
    "        'needs_audit_evidence': False,\n",
    "        'has_policy_expertise': False,\n",
    "        'stage': 'prototype'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Decision Framework Evaluation:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for ctx in contexts:\n",
    "    result = should_use_automated_testing(ctx)\n",
    "    print(f\"\\nProject: {ctx['name']}\")\n",
    "    print(f\"Recommendation: {result['recommendation']} (Score: {result['score']})\")\n",
    "    print(\"Reasoning:\")\n",
    "    for reason in result['reasons']:\n",
    "        print(f\"  - {reason}\")\n",
    "\n",
    "# Expected: FinTech RECOMMEND, Internal Tools NOT RECOMMENDED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 12: Summary & Next Steps\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "1. ✅ **Policy-as-Code** - Transformed compliance from docs to executable policies\n",
    "2. ✅ **OPA/Rego** - Implemented industry-standard policy engine\n",
    "3. ✅ **PII Detection** - Regex and optional ML-based detection\n",
    "4. ✅ **Test Pyramid** - 70% unit, 20% integration, 10% E2E strategy\n",
    "5. ✅ **CI/CD Integration** - Automated gates preventing violations\n",
    "6. ✅ **Audit Evidence** - Auto-generated test results for compliance\n",
    "\n",
    "### Key Metrics Achieved\n",
    "\n",
    "- **95%+ violation prevention** in CI/CD\n",
    "- **16x faster audit prep** (8 hours → 30 minutes)\n",
    "- **2-5 minute test execution** per pipeline run\n",
    "- **55-77 automated tests** per deployment\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Immediate:**\n",
    "   - Install OPA binary for full functionality\n",
    "   - Run test suite: `pytest tests/`\n",
    "   - Review example policies in README\n",
    "\n",
    "2. **This Week:**\n",
    "   - Integrate with M3.1 monitoring dashboards\n",
    "   - Set up CI/CD compliance gates\n",
    "   - Write first custom Rego policy\n",
    "\n",
    "3. **This Month:**\n",
    "   - Complete M3.3: Incident Response\n",
    "   - Conduct first automated audit evidence review\n",
    "   - Expand test coverage to access control and retention policies\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [OPA Documentation](https://www.openpolicyagent.org/docs/latest/)\n",
    "- [Rego Playground](https://play.openpolicyagent.org/)\n",
    "- [Presidio Documentation](https://microsoft.github.io/presidio/)\n",
    "- Module README: `../README.md`\n",
    "\n",
    "---\n",
    "\n",
    "**Remember:** Automated testing catches ~95% of violations. Still need:\n",
    "- M3.1 dashboards for runtime detection\n",
    "- Annual third-party audits\n",
    "- Incident response for the 5% that slip through\n",
    "\n",
    "**Prevention over detection, but never 100%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\"*60)\n",
    "print(\"L3 M3.2: Automated Compliance Testing - Complete\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n✓ Module completed successfully!\\n\")\n",
    "print(\"Key Takeaways:\")\n",
    "print(\"  1. Policy-as-code transforms compliance from docs to executable tests\")\n",
    "print(\"  2. OPA/Rego provides industry-standard policy engine\")\n",
    "print(\"  3. Test pyramid ensures comprehensive coverage (70/20/10)\")\n",
    "print(\"  4. CI/CD integration prevents 95%+ violations pre-deployment\")\n",
    "print(\"  5. Automated evidence reduces audit prep 16x (8h → 30min)\")\n",
    "print(\"\\nNext Module: M3.3 - Incident Response\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
